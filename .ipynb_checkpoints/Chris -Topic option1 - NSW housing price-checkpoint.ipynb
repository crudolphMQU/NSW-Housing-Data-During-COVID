{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b83fe44",
   "metadata": {},
   "source": [
    "### MEETING 4/9/21\n",
    "- we have a tute for map plots. Ken wants to explore that when he has the time probably after w7. \n",
    "\n",
    "- trying to finish the proposal asap. \n",
    "\n",
    "- what factors contribute to the house rent price? family size, income, \n",
    "\n",
    "- relationship between rental price and buying price. \n",
    "\n",
    "- real estate website will take your previous searches to suggest similar options. \n",
    "\n",
    "- do we want to look at the data as a buyer or a seller? \n",
    "\n",
    "- we didnt use the previous census data because it might be too old. \n",
    "\n",
    "- what if we use the census before the previous census, build a model off it then use it to predict the previous model? (ask steve what he thinks) \n",
    "\n",
    "- what are the issues with the datasets?\n",
    "        Alexis: the scoping, the technique or the data? are we going to limit to Greater sydney  region. Each quarter means less observations ./ roles. \n",
    "        How do bracket variables work in building models? \n",
    "        is 2 years back enough? \n",
    "        \n",
    "        felix:dont want data too old because it might not be representative, time after 2008-2009 is good because thats when banks started their monitoring policies. \n",
    "        \n",
    "        \n",
    "        \n",
    "- will the previous years be in the same format as what we have now? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1386b68",
   "metadata": {},
   "source": [
    "### MEETING  12/9 \n",
    "- felix has coworkers that will check our models to see which will make more sense\n",
    "- use a singler quarter to split train / test or postcode / lga? we have a map so its just a matter of joining it with the master table. Will experiment with either of them. \n",
    "- we are starting to join rent and sales DFs. (pending cleaning on rent data)\n",
    "- Clean our own data of the feature we want to bring into to the model. we should talk about the features we're going to use and why we're using them. \n",
    "- Felix and ken are starting to work on cleaning the features and work on the proposal. \n",
    "- chris and alexis is finalising the cleaning and the clleaning function. will then merge the DFs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed267543",
   "metadata": {},
   "source": [
    "### MEETING 15/9/21\n",
    "\n",
    "ADD appropriate issue numbers to the old data files for sales and rent. will have to inclulde in the functioin that the rent is 1 issue behind compared to the salles files. issue is on the front pageg of the excel sheet. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd99bb4",
   "metadata": {},
   "source": [
    "### DISCUSSION POINT: ###\n",
    "\n",
    "IF TO USE THIS HOUSING DATA\n",
    "1. **Use postcode or LGA** - LGA usually covers larger area than one postcode, which might mean less pointy data, but makes better sense to readers; on the other hand one postcode corresponds to multiple suburbs, can be hard to describe (below preliminary analysis was done using postcode for simplicity). \n",
    "Postcode to LGA Mapping [here](https://www.dva.gov.au/sites/default/files/Providers/nsworp.pdf).\n",
    "\n",
    "\n",
    "2. **Limit to Sydney Region or whole NSW** - the dataset contains data for all NSW regions (central coast, Wollogong etc.). Are we going to limit our analysis to Greater Syndey Region only or not? If so, need to figure out a method tease out Sydney LGAs / postcodes - scraping some gov. table (above mapping for example) and use the join method.\n",
    "\n",
    "\n",
    "3. **What variables from census to inclue and how** intuitively income, employment status, age, household size etc. We can merge in the master df and use RFE to decide which one is relevant. But the problem is - census data is categorical, you'll see what I mean by look at the example below of income - each bucket is one column, how to do modellilng using these bucket-level variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684fb5f",
   "metadata": {},
   "source": [
    "**DATA SOURCE:**\n",
    "\n",
    "[NSW Housing Rent and Sales](https://www.facs.nsw.gov.au/resources/statistics/rent-and-sales/back-issues)\n",
    "\n",
    "Sales data - renamed vs. original variable names:\n",
    "* <b>dwelling_type</b>: Dwelling Type\n",
    "* <b>25%_price</b>: First Quartile Sales Price (AUD 000s)\n",
    "* <b>50%_price</b>: Median Sales Price (AUD 000s)\n",
    "* <b>75%_price</b>: Third Quartile Sales Price (AUD 000s)\n",
    "* <b>mean_prce</b>: Mean Sales Price (AUD 000s)\n",
    "* <b>sales_no</b>: Number of Sales\n",
    "* <b>Qdelta_median</b>: Qtly change in Median\n",
    "* <b>Adelta_median</b>: Annual change in Median\n",
    "* <b>Qdelta_count</b>: Qtly change in Count\n",
    "* <b>Adelta_count</b>: Annual change in Count"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eaddb91",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5badc6e",
   "metadata": {},
   "source": [
    "# 1. Cleaning Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec098ca",
   "metadata": {},
   "source": [
    "### 1-1. Data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5ce75",
   "metadata": {},
   "source": [
    "Had to change some code to work for both 2017_2018 fiiles and 2019_2021 as there were minor differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36fb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c696a",
   "metadata": {},
   "source": [
    "\n",
    "### N.B. \n",
    "therer seems to be a probblem with reading the csv files. The first three have bad headers. I've tested this with removing the first three called files and still had the same problem. There are some files in the earlier years that have a mix of column headers \n",
    "\n",
    "the earlier files had no keys (issue number) so we had to change the file name manually. The ssue numbers were containied in the first page of the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef09ac3",
   "metadata": {},
   "source": [
    "help from https://stackoverflow.com/questions/14008440/how-to-extract-numbers-from-filename-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30ddc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88293234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salesCleanFn(dataFolderString,osString):\n",
    "    \n",
    "    #__________________________________________________________\n",
    "    # If operating system is windows\n",
    "    if osString == 'windows':\n",
    "        dataDir = \"Files\\\\\"\n",
    "        if dataFolderString[-1] != '\\\\':\n",
    "        #if the dataFolderString does not have a forward slash, add a forward slash to the string\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'\\\\'+'*.xlsx')\n",
    "        else:\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'*.xlsx')\n",
    "\n",
    "    #__________________________________________________________\n",
    "    # If operating system is mac / linux \n",
    "    else:\n",
    "        dataDir = \"Files/\"\n",
    "        if dataFolderString[-1] != '/':\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'/'+'*.xlsx')\n",
    "        else:\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'*.xlsx')\n",
    "#     print(fileNames)\n",
    "    \n",
    "    #__________________________________________________________\n",
    "    # Looping through the fileNames to read the excel sheets. \n",
    "    frames = []\n",
    "    masterDF = []\n",
    "\n",
    "    for i, fileString in enumerate(fileNames):\n",
    "        for j in range(0,8):\n",
    "            df = []\n",
    "            df = pd.read_excel(fileString, sheet_name=\"Postcode\", na_values='-', header=j)\n",
    "\n",
    "            if df.columns[0] == 'Postcode': # ...if the 'header' parameter has the correct j value...\n",
    "\n",
    "                # _____________________________________________________________________________________\n",
    "                # adding additional columns\n",
    "                regex = re.compile(r'\\d+') #finds all numbers in string\n",
    "                fileNumbers = regex.findall(fileString) #only works if the format of the \n",
    "                # filename is consistent. Stores the numbers in a list.\n",
    "                \n",
    "#                 print(fileNumbers)\n",
    "                df['key'] = 's'+fileNumbers[2] # fileNumbers type = string\n",
    "                year = fileNumbers[3] #type = string\n",
    "                \n",
    "                # the following statement searches for the month in the filename\n",
    "                # if the find() function does not find the month, it returns '-1'\n",
    "                # thus the use of !=-1. \n",
    "                if fileString.find('mar') !=-1 or fileString.find('Mar') !=-1:\n",
    "                    quarter = 'Q1'\n",
    "                elif fileString.find('jun') !=-1 or fileString.find('Jun') !=-1:\n",
    "                    quarter = 'Q2'\n",
    "                elif fileString.find('sep') !=-1 or fileString.find('Sep') !=-1:\n",
    "                    quarter = 'Q3'\n",
    "                elif fileString.find('dec') !=-1 or fileString.find('Dec') !=-1:\n",
    "                    quarter = 'Q4'\n",
    "                df['time_period'] = year + ' ' + quarter\n",
    "\n",
    "                df['year'] = year\n",
    "\n",
    "                df['quarter'] = quarter\n",
    "                \n",
    "                # some of the columns in the files are not the same, so we fix them here\n",
    "                column = 'Quarterly change in Median Sales Price'\n",
    "                newColumns = {'Quarterly change in Median Sales Price':'Qtly change in Median',\n",
    "                             'Annual change in Median Sales Price':'Annual change in Median',\n",
    "                             'Quarterly change in Count':'Qtly change in Count'}\n",
    "        \n",
    "                if column in df.columns:\n",
    "                    df.rename(columns = newColumns, inplace= True)\n",
    "                \n",
    "                # finally, putting the DF into a list, frames\n",
    "                frames.extend([df])\n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "    # _____________________________________________________________________________________\n",
    "    # putting all the DFs (frames) together to get a master DF\n",
    "    masterDF = pd.concat(frames)\n",
    "    # General cleaning\n",
    "    rename_cols= {'Postcode':'postcode', \n",
    "             'Dwelling Type':'dwelling_type', \n",
    "             \"First Quartile Sales Price\\n$'000s\" : '25%_price',\n",
    "             \"Median Sales Price\\n$'000s\" : 'median_price', \n",
    "             \"Third Quartile Sales Price\\n'000s\" : '75%_price',\n",
    "             \"Mean Sales Price\\n$'000s\" : 'mean_price',\n",
    "             'Sales\\nNo.':'sales_no',\n",
    "             'Qtly change in Median':'Qdelta_median',\n",
    "             'Annual change in Median':'Adelta_median',\n",
    "             'Qtly change in Count':'Qdelta_count',\n",
    "             'Annual change in Count':'Adelta_count'}\n",
    "    \n",
    "    masterDF.rename(columns=rename_cols, inplace=True) #rename the columns for easier referencing\n",
    "\n",
    "\n",
    "\n",
    "    masterDF = masterDF.drop(columns=['25%_price', '75%_price'], axis=1) # dropping unwanted columns\n",
    "    \n",
    "    masterDF.loc[masterDF['sales_no'].isnull(), 'sales_no'] = 5.0 #imputing NAN values. 5 is median of 0 and 10 being the \n",
    "    # range for null values in the dataset. \n",
    "    \n",
    "    # fixing the NAN values in the median and mean columns \n",
    "    keys = list(masterDF['key'].unique())\n",
    "\n",
    "    for k in keys:\n",
    "    # Total\n",
    "    # median\n",
    "        k_impMedianTotal = masterDF.loc[(masterDF['median_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Total') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'median_price'].median() # calculate imputer value \n",
    "\n",
    "        masterDF.loc[(masterDF['median_price'].isnull()) & \n",
    "                     (masterDF['dwelling_type']=='Total') &\n",
    "                     (masterDF['key']==k),\n",
    "                     'median_price']=k_impMedianTotal #impute\n",
    "\n",
    "    # mean\n",
    "        k_impMeanTotal = masterDF.loc[(masterDF['mean_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Total') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'median_price'].median()\n",
    "\n",
    "        masterDF.loc[(masterDF['mean_price'].isnull()) & \n",
    "                 (masterDF['dwelling_type']=='Total') &\n",
    "                 (masterDF['key']==k),\n",
    "                 'mean_price']=k_impMeanTotal #impute\n",
    "#         print(k_impMeanTotal)\n",
    "#         print('')\n",
    "#         print(k)\n",
    "\n",
    "    # Strata\n",
    "    # median\n",
    "        k_impMedianStrata = masterDF.loc[(masterDF['median_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Strata') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'median_price'].median()\n",
    "\n",
    "\n",
    "        masterDF.loc[(masterDF['median_price'].isnull()) & \n",
    "                     (masterDF['dwelling_type']=='Strata') &\n",
    "                     (masterDF['key']==k),\n",
    "                     'median_price']=k_impMedianStrata\n",
    "\n",
    "    # mean\n",
    "        k_impMeanStrata = masterDF.loc[(masterDF['mean_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Strata') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'mean_price'].median()\n",
    "\n",
    "        masterDF.loc[(masterDF['mean_price'].isnull()) & \n",
    "                     (masterDF['dwelling_type']=='Strata') &\n",
    "                     (masterDF['key']==k),\n",
    "                     'mean_price']=k_impMeanStrata\n",
    "\n",
    "    # Non-Strata\n",
    "    # median\n",
    "        k_impMedianNonStrata = masterDF.loc[(masterDF['median_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Non Strata') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'median_price'].median()\n",
    "\n",
    "        masterDF.loc[(masterDF['median_price'].isnull()) & \n",
    "                     (masterDF['dwelling_type']=='Non Strata') &\n",
    "                     (masterDF['key']==k),\n",
    "                     'median_price']=k_impMedianNonStrata\n",
    "\n",
    "    # mean\n",
    "        k_impMeanNonStrata = masterDF.loc[(masterDF['mean_price'].notna()) & \n",
    "                             (masterDF['dwelling_type']=='Non Strata') &\n",
    "                             (masterDF['key']==k),\n",
    "                             'mean_price'].median()\n",
    "\n",
    "        masterDF.loc[(masterDF['mean_price'].isnull()) & \n",
    "                     (masterDF['dwelling_type']=='Non Strata') &\n",
    "                     (masterDF['key']==k),\n",
    "                     'mean_price']=k_impMeanNonStrata\n",
    "        continue\n",
    "\n",
    "    masterDF.loc[masterDF['sales_no'] == 's', 'sales_no'] = 20.0 # Replace 's' with the median of \n",
    "    # 10 and 30 since there are quite a few\n",
    "\n",
    "    masterDF['sales_no'] = masterDF['sales_no'].astype(float) # Cast type as float\n",
    "\n",
    "    total = masterDF.loc[masterDF['dwelling_type']=='Total'] # Separate dwelling types\n",
    "    strata = masterDF.loc[masterDF['dwelling_type']=='Strata']\n",
    "    nstrata = masterDF.loc[masterDF['dwelling_type']=='Non Strata'] \n",
    "\n",
    "    return masterDF, total, strata, nstrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42f5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesOld, salesOld_total, salesOld_strata, salesOld_nStrata  = salesCleanFn('Sales/2017_2018', 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615fa139",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesOld.to_csv('Files/sales_2017_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd43bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesOld_total.to_csv('Files/salesTotal_2017_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77fe8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesOld_strata.to_csv('Files/salesStrata_2017_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0c2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesOld_nStrata.to_csv('Files/salesNstrata_2017_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0d73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesNew, salesNew_total, salesNew_strata,  salesNew_nStrata =  salesCleanFn('Sales/2019_2021', 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57320b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesNew.to_csv('Files/sales_2019_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6735c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesNew_total.to_csv('Files/salesTotal_2019_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0388bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesNew_strata.to_csv('Files/salesStrata_2019_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed03d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesNew_nStrata.to_csv('Files/salesNstrata_2019_2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaba546c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>median_price</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>sales_no</th>\n",
       "      <th>Qdelta_median</th>\n",
       "      <th>Adelta_median</th>\n",
       "      <th>Qdelta_count</th>\n",
       "      <th>Adelta_count</th>\n",
       "      <th>key</th>\n",
       "      <th>time_period</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Total</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>-0.1043</td>\n",
       "      <td>-0.1488</td>\n",
       "      <td>s128</td>\n",
       "      <td>2019 Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>680.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s128</td>\n",
       "      <td>2019 Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>Strata</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>-0.0340</td>\n",
       "      <td>-0.0920</td>\n",
       "      <td>-0.0734</td>\n",
       "      <td>-0.1062</td>\n",
       "      <td>s128</td>\n",
       "      <td>2019 Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>Total</td>\n",
       "      <td>641.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.0642</td>\n",
       "      <td>-0.1097</td>\n",
       "      <td>-0.1333</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>s128</td>\n",
       "      <td>2019 Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>Strata</td>\n",
       "      <td>641.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.0642</td>\n",
       "      <td>-0.1097</td>\n",
       "      <td>-0.1333</td>\n",
       "      <td>-0.3158</td>\n",
       "      <td>s128</td>\n",
       "      <td>2019 Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>2877</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>195.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.0714</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.5385</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>s136</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>2879</td>\n",
       "      <td>Total</td>\n",
       "      <td>760.5</td>\n",
       "      <td>760.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s136</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>2879</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>843.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s136</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>2880</td>\n",
       "      <td>Total</td>\n",
       "      <td>120.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>s136</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>2880</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>120.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>s136</td>\n",
       "      <td>2021 Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12445 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postcode dwelling_type  median_price  mean_price  sales_no  \\\n",
       "0         2000         Total        1160.0      1348.0     103.0   \n",
       "1         2000    Non Strata         680.0       720.0       5.0   \n",
       "2         2000        Strata        1135.0      1322.0     101.0   \n",
       "3         2007         Total         641.0       517.0      20.0   \n",
       "4         2007        Strata         641.0       517.0      20.0   \n",
       "...        ...           ...           ...         ...       ...   \n",
       "1422      2877    Non Strata         195.0       212.0      20.0   \n",
       "1423      2879         Total         760.5       760.5       5.0   \n",
       "1424      2879    Non Strata         843.0       888.0       5.0   \n",
       "1425      2880         Total         120.0       146.0     107.0   \n",
       "1426      2880    Non Strata         120.0       146.0     107.0   \n",
       "\n",
       "      Qdelta_median  Adelta_median  Qdelta_count  Adelta_count   key  \\\n",
       "0           -0.0169        -0.1375       -0.1043       -0.1488  s128   \n",
       "1               NaN            NaN           NaN           NaN  s128   \n",
       "2           -0.0340        -0.0920       -0.0734       -0.1062  s128   \n",
       "3           -0.0642        -0.1097       -0.1333       -0.3158  s128   \n",
       "4           -0.0642        -0.1097       -0.1333       -0.3158  s128   \n",
       "...             ...            ...           ...           ...   ...   \n",
       "1422        -0.0714         0.3636        0.5385        4.0000  s136   \n",
       "1423            NaN            NaN           NaN           NaN  s136   \n",
       "1424            NaN            NaN           NaN           NaN  s136   \n",
       "1425        -0.0323        -0.0400        0.1146        0.5070  s136   \n",
       "1426        -0.0323        -0.0400        0.1146        0.5070  s136   \n",
       "\n",
       "     time_period  year quarter  \n",
       "0        2019 Q1  2019      Q1  \n",
       "1        2019 Q1  2019      Q1  \n",
       "2        2019 Q1  2019      Q1  \n",
       "3        2019 Q1  2019      Q1  \n",
       "4        2019 Q1  2019      Q1  \n",
       "...          ...   ...     ...  \n",
       "1422     2021 Q1  2021      Q1  \n",
       "1423     2021 Q1  2021      Q1  \n",
       "1424     2021 Q1  2021      Q1  \n",
       "1425     2021 Q1  2021      Q1  \n",
       "1426     2021 Q1  2021      Q1  \n",
       "\n",
       "[12445 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10d5eb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postcode</th>\n",
       "      <th>dwelling_type</th>\n",
       "      <th>median_price</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>sales_no</th>\n",
       "      <th>Qdelta_median</th>\n",
       "      <th>Adelta_median</th>\n",
       "      <th>Qdelta_count</th>\n",
       "      <th>Adelta_count</th>\n",
       "      <th>key</th>\n",
       "      <th>time_period</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Total</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1516.328059</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>-0.3250</td>\n",
       "      <td>-0.3112</td>\n",
       "      <td>s122</td>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>Strata</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>1516.328059</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.5553</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>-0.2703</td>\n",
       "      <td>s122</td>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>Total</td>\n",
       "      <td>817.5</td>\n",
       "      <td>804.448333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.1090</td>\n",
       "      <td>-0.1572</td>\n",
       "      <td>-0.4462</td>\n",
       "      <td>-0.3455</td>\n",
       "      <td>s122</td>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>Strata</td>\n",
       "      <td>817.5</td>\n",
       "      <td>804.448333</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.0815</td>\n",
       "      <td>-0.1528</td>\n",
       "      <td>-0.4194</td>\n",
       "      <td>-0.3208</td>\n",
       "      <td>s122</td>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Total</td>\n",
       "      <td>995.0</td>\n",
       "      <td>1061.807024</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.1087</td>\n",
       "      <td>-0.1277</td>\n",
       "      <td>s122</td>\n",
       "      <td>2017 Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>2877</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>194.0</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>-0.2941</td>\n",
       "      <td>s127</td>\n",
       "      <td>2018 Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>2880</td>\n",
       "      <td>Total</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>-0.1735</td>\n",
       "      <td>s127</td>\n",
       "      <td>2018 Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>2880</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>-0.1735</td>\n",
       "      <td>s127</td>\n",
       "      <td>2018 Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>3644</td>\n",
       "      <td>Total</td>\n",
       "      <td>680.0</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s127</td>\n",
       "      <td>2018 Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>3644</td>\n",
       "      <td>Non Strata</td>\n",
       "      <td>710.0</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s127</td>\n",
       "      <td>2018 Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8272 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      postcode dwelling_type  median_price   mean_price  sales_no  \\\n",
       "0         2000         Total        1350.0  1516.328059     135.0   \n",
       "1         2000        Strata        1350.0  1516.328059     135.0   \n",
       "2         2007         Total         817.5   804.448333      36.0   \n",
       "3         2007        Strata         817.5   804.448333      36.0   \n",
       "4         2008         Total         995.0  1061.807024      41.0   \n",
       "...        ...           ...           ...          ...       ...   \n",
       "1367      2877    Non Strata         194.0   197.000000      20.0   \n",
       "1368      2880         Total         133.0   138.000000      81.0   \n",
       "1369      2880    Non Strata         133.0   138.000000      81.0   \n",
       "1370      3644         Total         680.0   680.000000       5.0   \n",
       "1371      3644    Non Strata         710.0   743.000000       5.0   \n",
       "\n",
       "      Qdelta_median  Adelta_median  Qdelta_count  Adelta_count   key  \\\n",
       "0            0.1345         0.4746       -0.3250       -0.3112  s122   \n",
       "1            0.1431         0.5553       -0.3182       -0.2703  s122   \n",
       "2           -0.1090        -0.1572       -0.4462       -0.3455  s122   \n",
       "3           -0.0815        -0.1528       -0.4194       -0.3208  s122   \n",
       "4           -0.0005         0.0205       -0.1087       -0.1277  s122   \n",
       "...             ...            ...           ...           ...   ...   \n",
       "1367         0.2360         0.2263        0.2000       -0.2941  s127   \n",
       "1368         0.1667         0.4301        0.0658       -0.1735  s127   \n",
       "1369         0.1667         0.4301        0.0658       -0.1735  s127   \n",
       "1370            NaN            NaN           NaN           NaN  s127   \n",
       "1371            NaN            NaN           NaN           NaN  s127   \n",
       "\n",
       "     time_period  year quarter  \n",
       "0        2017 Q3  2017      Q3  \n",
       "1        2017 Q3  2017      Q3  \n",
       "2        2017 Q3  2017      Q3  \n",
       "3        2017 Q3  2017      Q3  \n",
       "4        2017 Q3  2017      Q3  \n",
       "...          ...   ...     ...  \n",
       "1367     2018 Q4  2018      Q4  \n",
       "1368     2018 Q4  2018      Q4  \n",
       "1369     2018 Q4  2018      Q4  \n",
       "1370     2018 Q4  2018      Q4  \n",
       "1371     2018 Q4  2018      Q4  \n",
       "\n",
       "[8272 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salesOld"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852eb97",
   "metadata": {},
   "source": [
    "# CLEANING RENT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f3732",
   "metadata": {},
   "source": [
    "### cleaning function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10e400",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "os.path.join('files','sales')\n",
    "\n",
    "will put the appropriate slashes depending on your OS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "893d2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rentCleanFn(dataFolderString,osString):\n",
    "        \n",
    "    #__________________________________________________________\n",
    "    # If operating system is windows\n",
    "    if osString == 'windows':\n",
    "        dataDir = \"Files\\\\\"\n",
    "        if dataFolderString[-1] != '\\\\':\n",
    "        #if the dataFolderString does not have a forward slash, add a forward slash to the string\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'\\\\'+'*.xlsx')\n",
    "        else:\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'*.xlsx')\n",
    "\n",
    "    #__________________________________________________________\n",
    "    # If operating system is mac / linux \n",
    "    else:\n",
    "        dataDir = \"Files/\"\n",
    "        if dataFolderString[-1] != '/':\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'/'+'*.xlsx')\n",
    "        else:\n",
    "            fileNames = glob.glob(dataDir+dataFolderString+'*.xlsx')\n",
    "#     print(fileNames)\n",
    "    \n",
    "    #__________________________________________________________\n",
    "    # Looping through the fileNames to read the excel sheets. \n",
    "    frames = []\n",
    "    masterDF = []\n",
    "    \n",
    "    for i, fileString in enumerate(fileNames):\n",
    "        for j in range(0,8):\n",
    "            df = []\n",
    "            df = pd.read_excel(fileString, sheet_name=\"Postcode\", na_values='-', header=j)\n",
    "\n",
    "            if df.columns[0] == 'Postcode': # ...if the 'header' parameter has the correct j value...\n",
    "\n",
    "                # adding additional columns\n",
    "                regex = re.compile(r'\\d+') #finds all numbers in string\n",
    "                fileNumbers = regex.findall(fileString)\n",
    "                \n",
    "                df['key'] = 'r'+str(int(fileNumbers[2]) +1) # fileNumbers type = string\n",
    "    \n",
    "                \n",
    "        \n",
    "                # some of the columns in the files are not the same, so we fix them here\n",
    "                column = 'Bedroom Numbers'\n",
    "                newColumns = {'Bedroom Numbers':'Number of Bedrooms'}\n",
    "        \n",
    "                if column in df.columns:\n",
    "                    df.rename(columns = newColumns, inplace= True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                frames.extend([df])# putting the DF into a list, frames\n",
    "\n",
    "            \n",
    "              \n",
    "\n",
    "\n",
    "\n",
    "    masterDF = pd.concat(frames)\n",
    "    \n",
    "    # droppinig this column as we've confirmed there's an issue with the raw csv file. \n",
    "    if 'Unnamed: 10' in masterDF.columns:\n",
    "        masterDF=  masterDF.drop(columns='Unnamed: 10')\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    masterDF = masterDF.drop(columns=['First Quartile Weekly Rent for New Bonds\\n$',\n",
    "                          'Third Quartile Weekly Rent for New Bonds\\n$'],\n",
    "                axis=1)\n",
    "    \n",
    "    # Rename columns\n",
    "    rename_cols= {'Postcode':'postcode',\n",
    "                  'Dwelling Types':'dwelling_type', \n",
    "                  'Number of Bedrooms':'bed_number',\n",
    "                  'Median Weekly Rent for New Bonds\\n$': 'median_rent_newb',\n",
    "                  'New Bonds Lodged\\nNo.' : 'new_bonds_no',\n",
    "                  'Total Bonds Held\\nNo.': 'total_bonds_no',\n",
    "                  'Quarterly change in Median Weekly Rent':'Qdelta_median_rent',\n",
    "                  'Annual change in Median Weekly Rent':'Adelta_median_rent',\n",
    "                  'Quarterly change in New Bonds Lodged':'Qdelta_new_bonds',\n",
    "                  'Annual change in New Bonds Lodged':'Adelta_new_bonds'}\n",
    "    \n",
    "    masterDF.rename(columns=rename_cols,inplace=True)\n",
    "\n",
    "    masterDF_ag = masterDF.loc[(masterDF['bed_number']=='Total') & (masterDF['dwelling_type']=='Total')]\n",
    "    masterDF_ag = masterDF_ag.drop(columns=['bed_number','dwelling_type'], axis=1)\n",
    "    \n",
    "    # Impute 's' in 'new_bonds_no' and 'total_bonds_no' with 20\n",
    "    masterDF_ag.loc[masterDF_ag['new_bonds_no']=='s','new_bonds_no'] = 20.0\n",
    "    masterDF_ag.loc[masterDF_ag['total_bonds_no']=='s', 'total_bonds_no'] = 20.0\n",
    "\n",
    "    # Impute na in 'new_bonds_no' and 'total_bonds_no' with 5\n",
    "    masterDF_ag.loc[masterDF_ag['new_bonds_no'].isnull(),'new_bonds_no'] = 5.0\n",
    "    masterDF_ag.loc[masterDF_ag['total_bonds_no'].isnull(), 'total_bonds_no'] = 5.0\n",
    "\n",
    "    # Cast both variables as float (was object)\n",
    "    masterDF_ag['new_bonds_no'] = masterDF_ag['new_bonds_no'].astype(float)\n",
    "    masterDF_ag['total_bonds_no'] = masterDF_ag['total_bonds_no'].astype(float)\n",
    "\n",
    "    # Impute na in 'median_rent' with median of the column\n",
    "    masterDF_ag['median_rent_newb'].fillna(masterDF_ag['median_rent_newb'].median(), inplace=True)\n",
    "    \n",
    "\n",
    "    # Set postcode as index\n",
    "    \n",
    "    masterDF_ag = masterDF_ag.set_index('postcode')\n",
    "    return masterDF_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf83d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time taken to run the function: 159.7390685081482\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "rentNew = rentCleanFn('Rent/2019_2021', 'windows')\n",
    "\n",
    "end= time.time()\n",
    "print('')\n",
    "print(f'time taken to run the function: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0addd87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.40056586265564\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "rentOld  = rentCleanFn('Rent/2017_2018', 'windows')\n",
    "\n",
    "end= time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c55717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentOld.to_csv('Files/rent_2017_2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90d78449",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentNew.to_csv('Files/rent_2019_2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6724d24",
   "metadata": {},
   "source": [
    "### hard code method"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4aa158fc",
   "metadata": {},
   "source": [
    "r135 = \"Files/Rent/2019_2021/Issue-130-2019-Rent-tables-December-Quarter-2019.xlsx\"\n",
    "r135 = pd.read_excel(r135, sheet_name=\"Postcode\", na_values='-', header=4)\n",
    "r135"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1e7da3e",
   "metadata": {},
   "source": [
    "# Read into df\n",
    "\n",
    "# Drop unwanted columns\n",
    "r135 = r135.drop(columns=['First Quartile Weekly Rent for New Bonds\\n$',\n",
    "                          'Third Quartile Weekly Rent for New Bonds\\n$'],\n",
    "                axis=1)\n",
    "\n",
    "# Rename columns\n",
    "rename_cols= {'Postcode':'postcode',\n",
    "              'Dwelling Types':'dwelling_type', \n",
    "              'Number of Bedrooms':'bed_number',\n",
    "              'Median Weekly Rent for New Bonds\\n$': 'median_rent_newb',\n",
    "              'New Bonds Lodged\\nNo.' : 'new_bonds_no',\n",
    "              'Total Bonds Held\\nNo.': 'total_bonds_no',\n",
    "              'Quarterly change in Median Weekly Rent':'Qdelta_median_rent',\n",
    "              'Annual change in Median Weekly Rent':'Adelta_median_rent',\n",
    "              'Quarterly change in New Bonds Lodged':'Qdelta_new_bonds',\n",
    "              'Annual change in New Bonds Lodged':'Adelta_new_bonds'}\n",
    "r135.rename(columns=rename_cols,inplace=True)\n",
    "\n",
    "r135.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38b788a0",
   "metadata": {},
   "source": [
    "# Check df shape and null values\n",
    "print(r135.shape)\n",
    "print(r135.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d08a9",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "Note that an alarming 3/4 of the data has null values. This is because the data is broken down to very granular level - first by dwelling type (Total, house, townhouse, flat/unit, other) and then by bed_numbers (see below cell).m\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ab9f1b5",
   "metadata": {},
   "source": [
    "print(r135.groupby('dwelling_type').size(),'\\n')\n",
    "print(r135.groupby('bed_number').size())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f947d9cb",
   "metadata": {},
   "source": [
    "# Aggregate dwelling type and bed number, save as new df r135_ag\n",
    "\n",
    "r135_ag = r135.loc[(r135['bed_number']=='Total') & (r135['dwelling_type']=='Total')]\n",
    "r135_ag = r135_ag.drop(columns=['bed_number','dwelling_type'], axis=1) # Drop bed_number and dwelling_type\n",
    "\n",
    "print(r135_ag.shape)\n",
    "print(r135_ag.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96123b",
   "metadata": {},
   "source": [
    "By aggregating the data, we're able to bring down the proportion of na from 3/4 to around 1/3. But there's still need for imputation. According to the data interpretation note:\n",
    "\n",
    "<em><b>\"For confidentiality, we don't report rents in any geographical area where the number of new bonds is 10 or less (shown as na). Statistics calculated from sample sizes between 10 an 30 are shown by an 's' in the relevant table\"</b></em>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d598bbd",
   "metadata": {},
   "source": [
    "print(\"number of 's' in new_bonds_no:\", r135_ag.loc[r135_ag['new_bonds_no']=='s'].shape[0])\n",
    "print(\"number of 's' in total_bonds_noA:\", r135_ag.loc[r135_ag['total_bonds_no']=='s'].shape[0],\"\\n\")\n",
    "print(\"number of na in new_bonds_no:\", r135_ag.loc[r135_ag['new_bonds_no'].isnull()].shape[0])\n",
    "print(\"number of na in total_bonds_no:\", r135_ag.loc[r135_ag['total_bonds_no'].isnull()].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa581be",
   "metadata": {},
   "source": [
    "<b>IMPUTATION</b>\n",
    "* For 'new_bonds_no' and 'total_bonds_no' columns:\n",
    "    * Impute na with 5\n",
    "    * Impute s with 20\n",
    "    \n",
    "* For 'median_rent_newb' column\n",
    "    * Impute na with median of rents of all POAs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccdbbb2f",
   "metadata": {},
   "source": [
    "# Impute 's' in 'new_bonds_no' and 'total_bonds_no' with 20\n",
    "r135_ag.loc[r135_ag['new_bonds_no']=='s','new_bonds_no'] = 20.0\n",
    "r135_ag.loc[r135_ag['total_bonds_no']=='s', 'total_bonds_no'] = 20.0\n",
    "\n",
    "# Impute na in 'new_bonds_no' and 'total_bonds_no' with 5\n",
    "r135_ag.loc[r135_ag['new_bonds_no'].isnull(),'new_bonds_no'] = 5.0\n",
    "r135_ag.loc[r135_ag['total_bonds_no'].isnull(), 'total_bonds_no'] = 5.0\n",
    "\n",
    "# Cast both variables as float (was object)\n",
    "r135_ag['new_bonds_no'] = r135_ag['new_bonds_no'].astype(float)\n",
    "r135_ag['total_bonds_no'] = r135_ag['total_bonds_no'].astype(float)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e31fd4c",
   "metadata": {},
   "source": [
    "# Impute na in 'median_rent' with median of the column\n",
    "r135_ag['median_rent_newb'].fillna(r135_ag['median_rent_newb'].median(), inplace=True)\n",
    "\n",
    "# Check na in the df again\n",
    "print(r135_ag.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "097ef35a",
   "metadata": {},
   "source": [
    "# Prepare for merging\n",
    "r135_ag['key_r'] = 'r135' # Add key\n",
    "\n",
    "# Set postcode as index\n",
    "r135_ag = r135_ag.set_index('postcode')\n",
    "r135_ag.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b466a244",
   "metadata": {},
   "source": [
    "### sales data original cleaning process, hard code method"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7162346",
   "metadata": {},
   "source": [
    "s136 = \"Files/Sales/2019_2021/Issue-136-Sales-tables-March-2021-quarter.xlsx\"\n",
    "s135 = \"Files/Sales/2019_2021/Issue-135-Sales-tables-December-2020-quarter.xlsx\"\n",
    "s134 = \"Files/Sales/2019_2021/Issue-134-Sales-tables-September-2020-quarter.xlsx\"\n",
    "s133 = \"Files/Sales/2019_2021/Issue-133-Sales-tables-June-2020-quarter.xlsx\"\n",
    "s132 = \"Files/Sales/2019_2021/Issue-132-Sales-tables-March-2020-quarter.xlsx\"\n",
    "s131 = \"Files/Sales/2019_2021/Issue-131-Sales-tables-December-quarter-2019.xlsx\"\n",
    "s130 = \"Files/Sales/2019_2021/Issue-130-Sales-tables-September-quarter-2019.xlsx\"\n",
    "s129 = \"Files/Sales/2019_2021/Issue-129-Sales-tables-June-quarter-2019.xlsx\"\n",
    "s128 = \"Files/Sales/2019_2021/Issue-128-Sales-tables-Mar-quarter-2019.xlsx\"\n",
    "\n",
    "# Read the two sheets into two separate dataframes\n",
    "s136 = pd.read_excel(s136, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s135 = pd.read_excel(s135, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s134 = pd.read_excel(s134, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s133 = pd.read_excel(s133, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s132 = pd.read_excel(s132, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s131 = pd.read_excel(s131, sheet_name=\"Postcode\", na_values='-', header=6)\n",
    "s130 = pd.read_excel(s130, sheet_name=\"Postcode\", na_values='-', header=5)\n",
    "s129 = pd.read_excel(s129, sheet_name=\"Postcode\", na_values='-', header=4)\n",
    "s128 = pd.read_excel(s128, sheet_name=\"Postcode\", na_values='-', header=4)\n",
    "\n",
    "# Sale prices in any geographical area where the number of sales is 10 or less were not shown for confidentiality\n",
    "# They were represented as '-' in the table\n",
    "\n",
    "print(\"Q1 2021(s136):\", s136.shape,\"\\n\",\n",
    "      \"Q4 2020(s135):\", s135.shape,\"\\n\",\n",
    "      \"Q3 2020(s134):\", s134.shape,\"\\n\",\n",
    "      \"Q2 2020(s133):\", s133.shape,\"\\n\",\n",
    "      \"Q1 2020(s132):\", s132.shape,\"\\n\",\n",
    "      \"Q4 2019(s131):\", s131.shape,\"\\n\",\n",
    "      \"Q3 2019(s130):\", s130.shape,\"\\n\",\n",
    "      \"Q2 2019(s129):\", s129.shape,\"\\n\",\n",
    "      \"Q1 2019(s128):\", s128.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14ec07b5",
   "metadata": {},
   "source": [
    "s136"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7c83e92",
   "metadata": {},
   "source": [
    "# Add time period and key columns before merging\n",
    "\n",
    "s136['key'] = 's136'\n",
    "s135['key'] = 's135'\n",
    "s134['key'] = 's134'\n",
    "s133['key'] = 's133'\n",
    "s132['key'] = 's132'\n",
    "s131['key'] = 's131'\n",
    "s130['key'] = 's130'\n",
    "s129['key'] = 's129'\n",
    "s128['key'] = 's128'\n",
    "\n",
    "s136['time_period'] = '2021 Q1'\n",
    "s135['time_period'] = '2020 Q4'\n",
    "s134['time_period'] = '2020 Q3'\n",
    "s133['time_period'] = '2020 Q2'\n",
    "s132['time_period'] = '2020 Q1'\n",
    "s131['time_period'] = '2019 Q4'\n",
    "s130['time_period'] = '2019 Q3'\n",
    "s129['time_period'] = '2019 Q2'\n",
    "s128['time_period'] = '2019 Q1'\n",
    "\n",
    "s136['year'] = '2021'\n",
    "s135['year'] = '2020'\n",
    "s134['year'] = '2020'\n",
    "s133['year'] = '2020'\n",
    "s132['year'] = '2020'\n",
    "s131['year'] = '2019'\n",
    "s130['year'] = '2019'\n",
    "s129['year'] = '2019'\n",
    "s128['year'] = '2019'\n",
    "\n",
    "s136['quarter'] = '1'\n",
    "s135['quarter'] = '4'\n",
    "s134['quarter'] = '3'\n",
    "s133['quarter'] = '2'\n",
    "s132['quarter'] = '1'\n",
    "s131['quarter'] = '4'\n",
    "s130['quarter'] = '3'\n",
    "s129['quarter'] = '2'\n",
    "s128['quarter'] = '1'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa44284a",
   "metadata": {},
   "source": [
    "# Merge sales file into one master file\n",
    "frames = [s128, s129, s130, s131, s132, s133, s134, s135, s136]\n",
    "s_master = pd.concat(frames)\n",
    "\n",
    "# Check master sales data's shape and dtypes\n",
    "print(\"s_master:\", s_master.shape, \"\\n\")\n",
    "print(s_master.dtypes)\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25873906",
   "metadata": {},
   "source": [
    "s_master\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6310445e",
   "metadata": {},
   "source": [
    "# Rename column for easier referencing\n",
    "rename_cols= {'Postcode':'postcode', \n",
    "             'Dwelling Type':'dwelling_type', \n",
    "             \"First Quartile Sales Price\\n$'000s\" : '25%_price',\n",
    "             \"Median Sales Price\\n$'000s\" : 'median_price', \n",
    "             \"Third Quartile Sales Price\\n'000s\" : '75%_price',\n",
    "             \"Mean Sales Price\\n$'000s\" : 'mean_price',\n",
    "             'Sales\\nNo.':'sales_no',\n",
    "             'Qtly change in Median':'Qdelta_median',\n",
    "             'Annual change in Median':'Adelta_median',\n",
    "             'Qtly change in Count':'Qdelta_count',\n",
    "             'Annual change in Count':'Adelta_count'}\n",
    "\n",
    "s_master.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# Drop unwanted columns\n",
    "s_master = s_master.drop(columns=['25%_price', '75%_price'], axis=1)\n",
    "\n",
    "s_master.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d5df37",
   "metadata": {},
   "source": [
    "Note that each postcode has 3 rows - Total, Strata, and Non-Strata. We'll later separate them into three dataframes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "017bc2eb",
   "metadata": {},
   "source": [
    "# Impute na  \n",
    "\n",
    "# na in 'sales_no': repace with 5 (median of 0 and 10)\n",
    "s_master.loc[s_master['sales_no'].isnull(), 'sales_no'] = 5.0\n",
    "s_master['sales_no'].isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e749b792",
   "metadata": {},
   "source": [
    "# na in 'median_price': replace with median of 'median_place' of the same dwelling_type of the same quarter\n",
    "keys = list(s_master['key'].unique())\n",
    "\n",
    "# Total\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['median_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Total') &\n",
    "                         (s_master['key']==k),\n",
    "                         'median_price'].median() # calculate imputer value \n",
    "    \n",
    "    s_master.loc[(s_master['median_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Total') &\n",
    "                 (s_master['key']==k),\n",
    "                 'median_price']=k_imp #impute\n",
    "    \n",
    "# Strata\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['median_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Strata') &\n",
    "                         (s_master['key']==k),\n",
    "                         'median_price'].median()\n",
    "    \n",
    "    s_master.loc[(s_master['median_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Strata') &\n",
    "                 (s_master['key']==k),\n",
    "                 'median_price']=k_imp\n",
    "\n",
    "# Non-Strata\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['median_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Non Strata') &\n",
    "                         (s_master['key']==k),\n",
    "                         'median_price'].median()\n",
    "    \n",
    "    s_master.loc[(s_master['median_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Non Strata') &\n",
    "                 (s_master['key']==k),\n",
    "                 'median_price']=k_imp\n",
    "\n",
    "s_master['median_price'].isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5652b9d2",
   "metadata": {},
   "source": [
    "frames[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f27aec8b",
   "metadata": {},
   "source": [
    "# na in 'mean_price': replace with median of 'mean_price' of the same dwelling_type of the same quarter\n",
    "\n",
    "# Total\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['mean_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Total') &\n",
    "                         (s_master['key']==k),\n",
    "                         'median_price'].median() # calculate imputer value \n",
    "    \n",
    "    s_master.loc[(s_master['mean_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Total') &\n",
    "                 (s_master['key']==k),\n",
    "                 'mean_price']=k_imp #impute\n",
    "    \n",
    "# Strata\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['mean_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Strata') &\n",
    "                         (s_master['key']==k),\n",
    "                         'mean_price'].median()\n",
    "    \n",
    "    s_master.loc[(s_master['mean_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Strata') &\n",
    "                 (s_master['key']==k),\n",
    "                 'mean_price']=k_imp\n",
    "\n",
    "# Non-Strata\n",
    "for k in keys:\n",
    "    k_imp = s_master.loc[(s_master['mean_price'].notna()) & \n",
    "                         (s_master['dwelling_type']=='Non Strata') &\n",
    "                         (s_master['key']==k),\n",
    "                         'mean_price'].median()\n",
    "    \n",
    "    s_master.loc[(s_master['mean_price'].isnull()) & \n",
    "                 (s_master['dwelling_type']=='Non Strata') &\n",
    "                 (s_master['key']==k),\n",
    "                 'mean_price']=k_imp\n",
    "    \n",
    "s_master['mean_price'].isnull().any()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6290dd4a",
   "metadata": {},
   "source": [
    "s_master[s_master['median_price'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51937d1",
   "metadata": {},
   "source": [
    "Sales number was read into the dataframe as string because accordingly to the Explanatory note \"statistics calculated from sample sizes between 10 and 30 are shown by an ‘s’ in the relevant table.  We suggest these data are treated with caution, particularly when assessing quarterly and annual changes.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fff11b2",
   "metadata": {},
   "source": [
    "# Replace 's' with the median of 10 and 30 since there're quite a few\n",
    "s_master.loc[s_master['sales_no'] == 's', 'sales_no'] = 20.0\n",
    "\n",
    "# Cast type as float\n",
    "s_master['sales_no'] = s_master['sales_no'].astype(float)\n",
    "\n",
    "s_master.describe().round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "211d9bc3",
   "metadata": {},
   "source": [
    "# Separate dwelling types\n",
    "s_total = s_master.loc[s_master['dwelling_type']=='Total']\n",
    "s_strata = s_master.loc[s_master['dwelling_type']=='Strata']\n",
    "s_nstrata = s_master.loc[s_master['dwelling_type']=='Non Strata']\n",
    "\n",
    "print('Total:', s_total.shape,\"\\n\",\n",
    "     'Strata:', s_strata.shape,\"\\n\",\n",
    "     'Non Strata:', s_nstrata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb032c8",
   "metadata": {},
   "source": [
    "### 1-2 Exploratory and descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4e925",
   "metadata": {},
   "source": [
    "#### A. <u>Total level trends - Number of houses sold</u> ####\n",
    "\n",
    "Key observations:\n",
    "* Total sales started decline in Q1 2020 when COVID first struck, reaching a low point in Jun-20\n",
    "* However, bounce back was quick to come in Q3'20 and achieved a 200% growth vs. SQLY in Q4'20\n",
    "\n",
    "To investigate more:\n",
    "* Difference between Strata and Non-Strata houses - *Strata property are mostly apartment and townhouse; while non-Strata are more likely to be houses - will explain more in the price section*\n",
    "* Calculate quarter-on-quarter growth rate -> show off of skills hehee"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf790cac",
   "metadata": {},
   "source": [
    "# Look at total number of sales by quarter and dwelling type\n",
    "sales_num = s_master.groupby(['time_period', \"dwelling_type\"])['sales_no'].sum().unstack()\n",
    "\n",
    "sales_num['Strata%'] = sales_num['Strata'] / sales_num['Total'] * 100\n",
    "sales_num['Non Strata%'] = sales_num['Non Strata'] / sales_num['Total'] * 100\n",
    "\n",
    "sales_num.round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33d3acd2",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "sns.set_theme()\n",
    "sales_num_plot = sales_num[['Strata', 'Non Strata']]\n",
    "\n",
    "\n",
    "sales_num_plot.plot(kind='bar', stacked=True,\n",
    "                    title = \"Number of property sold (NSW)\",\n",
    "                    legend=True,\n",
    "                    figsize=(8,5), \n",
    "                    rot=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff0a486",
   "metadata": {},
   "source": [
    "**CR**: for the first dot point, the trend should be starting at Q3, not Q1. There is a decline in Q1 and Q2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8fdfb",
   "metadata": {},
   "source": [
    "#### B. <u>Total level trends - average house price</u> ####\n",
    "Key observations:\n",
    "* Total (Strata + non-Strata) average price has been **trending up since Q1 2020** despite COVID\n",
    "* And this upward trend has been **driven by non-Strata houses**, the price of which have rocketed since Q2 2020\n",
    "* Strata properties (more likely to be apartment units/condos, terrace houses with shared common areas) on the contrary saw moderate increase in price in Q2'20 to Q4 then falling flat\n",
    "\n",
    "See [here](https://www.macquarie.com.au/home-loans/strata-properties-pros-and-cons.html) for more information on difference of Strata and non-strata property. \n",
    "\n",
    "**THIS IS IMPORTANT: suggesting that Strata and non-Strata house prices behave very diffirently and should probably be looked at separately in later regression analysis**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29c406d3",
   "metadata": {},
   "source": [
    "# Look at changes in average price\n",
    "price_mean = s_master.groupby(['time_period', 'dwelling_type'])['mean_price'].mean().unstack()\n",
    "price_mean.round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcf1fd4e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Visualisation - avg. price line chart\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.lineplot(data=price_mean)\n",
    "ax.set_title(\"Average price of houses sold by dwelling type\")\n",
    "ax.set_ylabel(\"avg. price (AUD 000s)\")\n",
    "ax.set_xlabel(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4677dae1",
   "metadata": {},
   "source": [
    "# Look at changes in median price to reduce the impact of potential outliers\n",
    "price_median = s_master.groupby(['time_period', 'dwelling_type'])['50%_price'].mean().unstack()\n",
    "price_median.round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0838c00f",
   "metadata": {},
   "source": [
    "# Visualisation - median price line chart\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.lineplot(data=price_median)\n",
    "ax.set_title(\"Price median of houses sold by dwelling type\")\n",
    "ax.set_ylabel(\"price (AUD 000s)\")\n",
    "ax.set_xlabel(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee04a1f",
   "metadata": {},
   "source": [
    "**CR** we want to find a way to get a map of sydney, link the postcodes, that way we can have a heatmap for better visualisation of sales around Sydney. Perhaps finding a website that gets the boundaries of the city with the post code. Is there a way to extract those boundaries? \n",
    "\n",
    "will have a look into this link : https://github.com/chrisberkhout/jvectormap_data_au"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45318e5b",
   "metadata": {},
   "source": [
    "#### C. <u>Suburb level (Q1 2021) - hottest and most expensive suburbs</u> ####\n",
    "\n",
    "**TO BE DONE:**\n",
    "* Scrape a table somewhere online to map postcode to the name of suburbs\n",
    "* Or make a decision to use the LGA tab of the raw data sheets (instead of the postcode sheet used here)\n",
    "* Investigate map visualisation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fa3eadd",
   "metadata": {},
   "source": [
    "# Group sales number by postcode\n",
    "sales_pc = s_total.groupby(['postcode','time_period'])[['sales_no']].sum().unstack()\n",
    "sales_pc.columns = sales_pc.columns.droplevel() #Drop column multiindex \n",
    "sales_pc = sales_pc.sort_values(by='2021 Q1', ascending=False)\n",
    "\n",
    "# 10 areas with most sales in Q1 2021\n",
    "sales_pc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15edd8",
   "metadata": {},
   "source": [
    "Roughly:\n",
    "* **2250**: part of Gosford LGA (Central Coast Region)\n",
    "* **2155**: part of Cherrybrook LGA \n",
    "* **2540**: Culburra LGA (Illawara Region)\n",
    "* **2170**: part of Liverpool LGA\n",
    "* **2650**: part of Junee LGA (Murrumbidgee Region)\n",
    "* **2251**: part of Wyong LGA (Central Coast Region)\n",
    "* **2560**: part of Campbelltown LGA \n",
    "* **2259**: part of Wyong LGA (Central Coast Region)\n",
    "* **2145**: part of Holroyd LGA \n",
    "* **2444**: part of Port Macquarie LGA (Mid North Coast Region)\n",
    "\n",
    "Look at how the price in these areas has changed."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e06b057",
   "metadata": {},
   "source": [
    "# Filter out top5 five postcode from the total dataset\n",
    "s5_list = list(sales_pc.head(5).index)\n",
    "s5 = s_total.loc[s_total['postcode'].isin(s5_list)]\n",
    "\n",
    "# Check the average sales price of each pc\n",
    "s5 = s5.groupby(['time_period','postcode'])['mean_price'].mean().unstack()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5f54260",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "ax = sns.lineplot(data=s5)\n",
    "ax.set_title(\"Average sales price of the 5 hottest areas\")\n",
    "ax.set_ylim(0,1200)\n",
    "ax.set_ylabel(\"Avg. priec(AUD 000s)\")\n",
    "ax.set_xlabel(None)\n",
    "ax.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee8c66",
   "metadata": {},
   "source": [
    "Next, look at average price by postcode."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c99dab5b",
   "metadata": {},
   "source": [
    "# Group price (total average) by postcode\n",
    "price_pc = s_total.groupby(['postcode','time_period'])[['mean_price']].mean().unstack()\n",
    "price_pc.columns = price_pc.columns.droplevel() #Drop column multiindex \n",
    "price_pc = price_pc.sort_values(by='2021 Q1', ascending=False)\n",
    "\n",
    "# Top 5 most expensive areas in Q1 2021\n",
    "price_pc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c64dee3",
   "metadata": {},
   "source": [
    "They are:\n",
    "* **2220:** Hurstville & Hurstville Grove\n",
    "* **2027:** Waverly LGA - Darling Point, Edgecliff & Point Piper (in\n",
    "* **2092:** Manly Warringah LGA - Seafort\n",
    "* **2030:** Waverly LGA - Rose Bay North, Vaucluse, Watsons Bay\n",
    "* **2107:** Manly Warringah LGA - NEWPORT BEACH, AVALON, AVALON BEACH, BILGOLA, CLAREVILLE, WHALE BEACH"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cb0cf02",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "price_pc5 = price_pc.head(5)\n",
    "price_pc5_tr = price_pc5.transpose()\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "ax = sns.lineplot(data=price_pc5_tr)\n",
    "ax.set_title(\"Top 5 NSW postcode with highest house prices in Q1 2021\")\n",
    "#ax.set_ylim(0,500)\n",
    "ax.set_ylabel(\"Avg. price (AUD 000s)\")\n",
    "ax.set_xlabel(None)\n",
    "ax.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577e338",
   "metadata": {},
   "source": [
    "### 1-3 Join Census Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e93f697",
   "metadata": {},
   "source": [
    "# Read weekly income data\n",
    "census_INCP = \"Files/Census/POA (UR) by INCP Toal Personal Income (Weekly).csv\"\n",
    "\n",
    "incp_raw = pd.read_csv(census_INCP, skiprows=9, nrows=11142,\n",
    "                       usecols=['POA (UR)', 'INCP Total Personal Income (weekly)', 'Count'])\n",
    "\n",
    "# Rename column for easier referencing\n",
    "incp_cols = {'POA (UR)':'postcode', 'INCP Total Personal Income (weekly)':'INCP_WK'}\n",
    "incp_raw.rename(columns=incp_cols, inplace=True)\n",
    "\n",
    "incp_raw.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac2c45a",
   "metadata": {},
   "source": [
    "incp = incp_raw.groupby(['postcode','INCP_WK'])['Count'].sum().unstack()\n",
    "incp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "593b00b4",
   "metadata": {},
   "source": [
    "# Remove the last row\n",
    "incp = incp[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140617b",
   "metadata": {},
   "source": [
    "**KS**: perhaps change the income brackets to low medium and high instead? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3235a51b",
   "metadata": {},
   "source": [
    "**CR**: should consider ordering the column incomes from lowest to highest or the other way around."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c523a49",
   "metadata": {},
   "source": [
    "# Clean column names\n",
    "income_cols= {'$1,000-$1,249 ($52,000-$64,999)' : '$1000-1249', \n",
    "            '$1,250-$1,499 ($65,000-$77,999)' : '$1250-1499',\n",
    "            '$1,500-$1,749 ($78,000-$90,999)' : '$1500-1749 ', \n",
    "            '$1,750-$1,999 ($91,000-$103,999)': '$1750-1999',\n",
    "            '$1-$149 ($1-$7,799)': '$1-149', \n",
    "            '$150-$299 ($7,800-$15,599)' : '$150-299',\n",
    "            '$2,000-$2,999 ($104,000-$155,999)':'$2000-2999',\n",
    "            '$3,000 or more ($156,000 or more)':'>=$3000', \n",
    "            '$300-$399 ($15,600-$20,799)':'$300-399',\n",
    "            '$400-$499 ($20,800-$25,999)':'$400-499', \n",
    "            '$500-$649 ($26,000-$33,799)':'$500-649',\n",
    "            '$650-$799 ($33,800-$41,599)':'$650-799', \n",
    "            '$800-$999 ($41,600-$51,999)':'$800-999'}\n",
    "\n",
    "incp.rename(columns=income_cols, inplace=True)\n",
    "\n",
    "# Combine 'not applicable' and 'not stated' into one column\n",
    "incp['total_na'] = incp['Not applicable'] + incp['Not stated']\n",
    "incp = incp.drop(columns=['Not applicable', 'Not stated'], axis=1)\n",
    "incp.head(1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "babeb09c",
   "metadata": {},
   "source": [
    "# Remove 'NSW' in the index and cast postcode to int64\n",
    "incp.reset_index(inplace=True)\n",
    "incp['postcode'] = incp['postcode'].str.split(\",\", n=1, expand=True)\n",
    "incp['postcode'] = incp['postcode'].astype('int64')\n",
    "incp = incp.set_index('postcode')\n",
    "\n",
    "incp.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0956384",
   "metadata": {},
   "source": [
    "**CR**: joining two DFs together, matching them by postcode. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fbb474f",
   "metadata": {},
   "source": [
    "# Join INCP with sales data\n",
    "s_join = s_master.join(incp, on='postcode')\n",
    "s_join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9457a",
   "metadata": {},
   "source": [
    "# 2. Rent data\n",
    "\n",
    "<u>USAGE POTENTIALS:</u>\n",
    "1. Analyse correlation of rental price and sales price "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d46bd2b9",
   "metadata": {},
   "source": [
    "rent = \"Files/Rent/Issue-135-Rent-tables-March-2021-quarter.xlsx\"\n",
    "rent_pc = pd.read_excel(rent, sheet_name=\"Postcode\", na_values='-', header=7)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d151872",
   "metadata": {},
   "source": [
    "# Rename column for easier referencing (rent)\n",
    "\n",
    "rename_cols= {'Postcode':'postcode', \n",
    "             'Dwelling Types':'dwelling_type', \n",
    "              'Number of Bedrooms':'bed_number',\n",
    "             'First Quartile Weekly Rent for New Bonds\\n$': '25%_wrent_newb',\n",
    "             'Median Weekly Rent for New Bonds\\n$': '50%_wrent_newb', \n",
    "             'Third Quartile Weekly Rent for New Bonds\\n$': \"75%_wrent_newb\",\n",
    "             'New Bonds Lodged\\nNo.' : 'new_bonds_number',\n",
    "              'Total Bonds Held\\nNo.': 'total_bonds_number',\n",
    "             'Sales\\nNo.':'sales_number'}\n",
    "\n",
    "rent_pc.rename(columns=rename_cols,inplace=True)\n",
    "rent_pc.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ee85a8c",
   "metadata": {},
   "source": [
    "# Check data types\n",
    "rent_pc.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77aea6bf",
   "metadata": {},
   "source": [
    "rent_pc.loc[rent_pc['new_bonds_number'] == 's', 'new_bonds_number'] = 20.0\n",
    "rent_pc.loc[rent_pc['total_bonds_number'] == 's', 'total_bonds_number'] = 20.0\n",
    "\n",
    "rent_pc['new_bonds_number'] = rent_pc['new_bonds_number'].astype(float)\n",
    "rent_pc['total_bonds_number'] = rent_pc['total_bonds_number'].astype(float)\n",
    "\n",
    "# Check data types again\n",
    "rent_pc.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1381e3ef",
   "metadata": {},
   "source": [
    "# Check unique values of dwelling type\n",
    "rent_pc.groupby('dwelling_type').size()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b53d892c",
   "metadata": {},
   "source": [
    "# Check unique values of bed_number\n",
    "rent_pc.groupby('bed_number').size()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbeef2f8",
   "metadata": {},
   "source": [
    "# checking shape of rent_pc and null values\n",
    "\n",
    "print(rent_pc.shape, \"\\n\")\n",
    "print(rent_pc.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "055ce2c4",
   "metadata": {},
   "source": [
    "# Check top 20 postcodes that have higest total bond number in Q1 2021\n",
    "tbonds_pc = rent_pc.groupby([\"postcode\", \"dwelling_type\"])['total_bonds_number'].sum().unstack()\n",
    "\n",
    "tbonds_pc.sort_values(by=\"Total\", ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a44c88c6",
   "metadata": {},
   "source": [
    "nbonds_pc = rent_pc.groupby([\"postcode\", \"dwelling_type\"])['new_bonds_number'].sum().unstack()\n",
    "nbonds_pc.sort_values(by='Total', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26a1b327",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
