{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e89d71",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Goals-&amp;-Methodology-(Felix)\" data-toc-modified-id=\"Goals-&amp;-Methodology-(Felix)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Goals &amp; Methodology (Felix)</a></span></li><li><span><a href=\"#Data-and-Variable-Explanation-(Alexis)\" data-toc-modified-id=\"Data-and-Variable-Explanation-(Alexis)-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Data and Variable Explanation (Alexis)</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Imports</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-&amp;-Cleaning-data-(Alexis:-what-we-did-and-refer-to-cleaning)\" data-toc-modified-id=\"Reading-&amp;-Cleaning-data-(Alexis:-what-we-did-and-refer-to-cleaning)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Reading &amp; Cleaning data (Alexis: what we did and refer to cleaning)</a></span></li><li><span><a href=\"#Variable-Analysis\" data-toc-modified-id=\"Variable-Analysis-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Variable Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Over-Time-(Felix)\" data-toc-modified-id=\"Over-Time-(Felix)-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Over Time (Felix)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sales-Number\" data-toc-modified-id=\"Sales-Number-2.2.1.1\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>Sales Number</a></span></li><li><span><a href=\"#Median-Rent\" data-toc-modified-id=\"Median-Rent-2.2.1.2\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>Median Rent</a></span></li><li><span><a href=\"#New-Bonds\" data-toc-modified-id=\"New-Bonds-2.2.1.3\"><span class=\"toc-item-num\">2.2.1.3&nbsp;&nbsp;</span>New Bonds</a></span></li><li><span><a href=\"#Construction-Costs\" data-toc-modified-id=\"Construction-Costs-2.2.1.4\"><span class=\"toc-item-num\">2.2.1.4&nbsp;&nbsp;</span>Construction Costs</a></span></li><li><span><a href=\"#Bond-Yields\" data-toc-modified-id=\"Bond-Yields-2.2.1.5\"><span class=\"toc-item-num\">2.2.1.5&nbsp;&nbsp;</span>Bond Yields</a></span></li><li><span><a href=\"#Interest-Rates\" data-toc-modified-id=\"Interest-Rates-2.2.1.6\"><span class=\"toc-item-num\">2.2.1.6&nbsp;&nbsp;</span>Interest Rates</a></span></li></ul></li><li><span><a href=\"#By-Postcode\" data-toc-modified-id=\"By-Postcode-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>By Postcode</a></span><ul class=\"toc-item\"><li><span><a href=\"#Median-Rent\" data-toc-modified-id=\"Median-Rent-2.2.2.1\"><span class=\"toc-item-num\">2.2.2.1&nbsp;&nbsp;</span>Median Rent</a></span></li><li><span><a href=\"#New-Bonds\" data-toc-modified-id=\"New-Bonds-2.2.2.2\"><span class=\"toc-item-num\">2.2.2.2&nbsp;&nbsp;</span>New Bonds</a></span></li><li><span><a href=\"#Age-Brackets\" data-toc-modified-id=\"Age-Brackets-2.2.2.3\"><span class=\"toc-item-num\">2.2.2.3&nbsp;&nbsp;</span>Age Brackets</a></span></li><li><span><a href=\"#ATSI\" data-toc-modified-id=\"ATSI-2.2.2.4\"><span class=\"toc-item-num\">2.2.2.4&nbsp;&nbsp;</span>ATSI</a></span></li><li><span><a href=\"#High-Income\" data-toc-modified-id=\"High-Income-2.2.2.5\"><span class=\"toc-item-num\">2.2.2.5&nbsp;&nbsp;</span>High Income</a></span></li><li><span><a href=\"#Year-of-Arrival\" data-toc-modified-id=\"Year-of-Arrival-2.2.2.6\"><span class=\"toc-item-num\">2.2.2.6&nbsp;&nbsp;</span>Year of Arrival</a></span></li><li><span><a href=\"#Non-AUS-Citizen\" data-toc-modified-id=\"Non-AUS-Citizen-2.2.2.7\"><span class=\"toc-item-num\">2.2.2.7&nbsp;&nbsp;</span>Non-AUS Citizen</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline-Regression-Model-(Chris)\" data-toc-modified-id=\"Baseline-Regression-Model-(Chris)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Baseline Regression Model (Chris)</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Cross Validation</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Improved-Model\" data-toc-modified-id=\"Improved-Model-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Improved Model</a></span></li></ul></li><li><span><a href=\"#Clustering-(Ken-&amp;-Felix)\" data-toc-modified-id=\"Clustering-(Ken-&amp;-Felix)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clustering (Ken &amp; Felix)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kmeans\" data-toc-modified-id=\"Kmeans-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Kmeans</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scaling-the-data\" data-toc-modified-id=\"Scaling-the-data-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Scaling the data</a></span></li><li><span><a href=\"#Optimal-Number-of-K:-Elbow-Method\" data-toc-modified-id=\"Optimal-Number-of-K:-Elbow-Method-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Optimal Number of K: Elbow Method</a></span></li><li><span><a href=\"#Apply-Algorithm\" data-toc-modified-id=\"Apply-Algorithm-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Apply Algorithm</a></span></li><li><span><a href=\"#Map\" data-toc-modified-id=\"Map-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Map</a></span></li></ul></li><li><span><a href=\"#Hierarchical-clustering\" data-toc-modified-id=\"Hierarchical-clustering-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Hierarchical clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scaling-the-data\" data-toc-modified-id=\"Scaling-the-data-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Scaling the data</a></span></li><li><span><a href=\"#Apply-algorithm\" data-toc-modified-id=\"Apply-algorithm-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Apply algorithm</a></span></li><li><span><a href=\"#Map\" data-toc-modified-id=\"Map-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Map</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Distinct-Models-per-Clusters\" data-toc-modified-id=\"Distinct-Models-per-Clusters-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Distinct Models per Clusters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-regression-based-on-KMeans-clusters\" data-toc-modified-id=\"Linear-regression-based-on-KMeans-clusters-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Linear regression based on KMeans clusters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-prep\" data-toc-modified-id=\"Data-prep-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Data prep</a></span></li><li><span><a href=\"#Model-on-the-2-Clusters\" data-toc-modified-id=\"Model-on-the-2-Clusters-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Model on the 2 Clusters</a></span></li><li><span><a href=\"#Hyperparameter-Tuning-Using-Grid-Search-Cross-Validation\" data-toc-modified-id=\"Hyperparameter-Tuning-Using-Grid-Search-Cross-Validation-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Hyperparameter Tuning Using Grid Search Cross-Validation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cluster-0\" data-toc-modified-id=\"Cluster-0-5.1.3.1\"><span class=\"toc-item-num\">5.1.3.1&nbsp;&nbsp;</span>Cluster 0</a></span></li><li><span><a href=\"#Cluster-1\" data-toc-modified-id=\"Cluster-1-5.1.3.2\"><span class=\"toc-item-num\">5.1.3.2&nbsp;&nbsp;</span>Cluster 1</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Classification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Assign-class-label---define-'high-growth-potential'-areas\" data-toc-modified-id=\"Assign-class-label---define-'high-growth-potential'-areas-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Assign class label - define 'high growth potential' areas</a></span></li><li><span><a href=\"#Random-Forest-Classifier\" data-toc-modified-id=\"Random-Forest-Classifier-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Random Forest Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Base-model\" data-toc-modified-id=\"Base-model-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Base model</a></span></li><li><span><a href=\"#Cross-validation\" data-toc-modified-id=\"Cross-validation-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Cross-validation</a></span></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Hyperparameter tuning</a></span></li><li><span><a href=\"#Tree\" data-toc-modified-id=\"Tree-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Tree</a></span></li><li><span><a href=\"#Map\" data-toc-modified-id=\"Map-6.2.5\"><span class=\"toc-item-num\">6.2.5&nbsp;&nbsp;</span>Map</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-6.2.6\"><span class=\"toc-item-num\">6.2.6&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Multi-layer-Perceptron-Classifier\" data-toc-modified-id=\"Multi-layer-Perceptron-Classifier-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Multi-layer Perceptron Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Base-model\" data-toc-modified-id=\"Base-model-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Base model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-6.3.1.1\"><span class=\"toc-item-num\">6.3.1.1&nbsp;&nbsp;</span>Cross Validation</a></span></li></ul></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tuning-Individual-Parameter\" data-toc-modified-id=\"Tuning-Individual-Parameter-6.3.2.1\"><span class=\"toc-item-num\">6.3.2.1&nbsp;&nbsp;</span>Tuning Individual Parameter</a></span></li><li><span><a href=\"#Tuning-with-GridSearch\" data-toc-modified-id=\"Tuning-with-GridSearch-6.3.2.2\"><span class=\"toc-item-num\">6.3.2.2&nbsp;&nbsp;</span>Tuning with GridSearch</a></span></li></ul></li><li><span><a href=\"#Best-MLPClassifier\" data-toc-modified-id=\"Best-MLPClassifier-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;</span>Best MLPClassifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Best-MLPClassifier---based-on-individual-tuning\" data-toc-modified-id=\"Best-MLPClassifier---based-on-individual-tuning-6.3.3.1\"><span class=\"toc-item-num\">6.3.3.1&nbsp;&nbsp;</span>Best MLPClassifier - based on individual tuning</a></span></li><li><span><a href=\"#Best-MLPClassifier---based-on-GridSearch\" data-toc-modified-id=\"Best-MLPClassifier---based-on-GridSearch-6.3.3.2\"><span class=\"toc-item-num\">6.3.3.2&nbsp;&nbsp;</span>Best MLPClassifier - based on GridSearch</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Results</a></span></li><li><span><a href=\"#Conclusion-and-Outlook\" data-toc-modified-id=\"Conclusion-and-Outlook-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conclusion and Outlook</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae51e48",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "State notebook purpose here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82372dd5",
   "metadata": {},
   "source": [
    "## Goals & Methodology (Felix)\n",
    "State the goals of the analysis and how it should be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183a3ab",
   "metadata": {},
   "source": [
    "## Data and Variable Explanation (Alexis)\n",
    "Explain the datasets used and the relevant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdddb24",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and write settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9247d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340b3e6",
   "metadata": {},
   "source": [
    "The data cleaning function takes a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45959add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run chrisDataCleanFunction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f8d27",
   "metadata": {},
   "source": [
    "We get the following DFs:\n",
    "\n",
    "- `salesNew`\n",
    "- `salesOld`\n",
    "- `salesNew_nStrata`\n",
    "- `salesNew_strata`\n",
    "- `salesNew_total`\n",
    "- `salesOld_nStrata`\n",
    "- `salesOld_strata`\n",
    "- `salesOld_total`\n",
    "- `rentNew`\n",
    "- `rentOld`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acbd9f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2d2c6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Reading & Cleaning data (Alexis: what we did and refer to cleaning)\n",
    "Read in the pre-processed unstacked dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa435a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reading in\n",
    "master = pd.read_csv(\"Files/Cleaned/Postcode-based/Master_Sales_Rent_2017Q4_2021Q1_pcFeatures.csv\")\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e7bd8",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7a00d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "master.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda856a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Variable Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f30130d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Over Time (Felix)\n",
    "Analyse possible relationships between target variable and features. Check if features are correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ab5ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pivot unstacked df to get aggregate values by time period\n",
    "pivot_time = pd.pivot_table(master,\n",
    "                            index=\"time_period\")\n",
    "pivot_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d637b9a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af8185",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# remove all census data as it does not change over time\n",
    "pivot_time = pivot_time.drop(['Adelta_count', \n",
    "                              'Adelta_median',\n",
    "                              'Adelta_median_rent', \n",
    "                              'Adelta_new_bonds', \n",
    "                              'Qdelta_count', \n",
    "                              'Qdelta_median',\n",
    "                              'Qdelta_median_rent', \n",
    "                              'Qdelta_new_bonds', \n",
    "                              'YARRP 1976-1995',\n",
    "                              'YARRP 1996-2005', \n",
    "                              'YARRP 2006-2016', \n",
    "                              'YARRP <1975', \n",
    "                              'population_2016', \n",
    "                              'postcode', \n",
    "                              '0-4yo', \n",
    "                              '15-24yo', \n",
    "                              '25-34yo', \n",
    "                              '35-54yo',\n",
    "                              '5-14yo', \n",
    "                              '55-64yo', \n",
    "                              '65+yo', \n",
    "                              'ATSI'],\n",
    "                            axis=1)\n",
    "pivot_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e5da0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_time.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2c87e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show correlation matrix for numeric data\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "postcode_corr = pivot_time[['mean_price', 'median_price', 'median_rent_newb', 'new_bonds_no', 'total_bonds_no', \n",
    "                            '10yBonds%', '2yBonds%', 'Rate', 'constr_index', 'sales_no']]\n",
    "\n",
    "matrix = np.triu(postcode_corr.corr())\n",
    "\n",
    "sns.heatmap(postcode_corr.corr(), \n",
    "            annot=True, # put coefficients in\n",
    "            fmt='.2g', # set number of decimals\n",
    "            vmin=-1, vmax=1, center=0, # rescale colorbar\n",
    "            cmap='RdYlGn', # set color palette\n",
    "            square=True, # set squares\n",
    "            mask=matrix) # display only lower triangular matrix\n",
    "plt.yticks(rotation=360)\n",
    "plt.xticks(rotation=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb06087",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Analysis of correlation with price:\n",
    "- There is a weak negative relationship between the __rent level__ and the sales price level. This implies that periods with higher rent prices tend to have lower sales prices. However, as mentioned, the relationship is rather weak.\n",
    "- There is a moderate positive relationship with the amount of __total bonds__.\n",
    "- There is a moderate to strong negative relationship with __10 Year Bonds__. This makes sense since in economic theory investors can choose from different asset classes. Government bonds are considered as ultra safe and hence represent a baseline of what investors expect as return since they can have the bond yield \"risk free\". If bond yields rise, the relative return of competing asset classes decrease, demand goes down, and price level will follow.\n",
    "- There is a strong negative relationship with __2 Year Bonds__. The reasoning is the same as for 10 year bonds. It is interesting, though, that the relationship for shorter duration bonds seems stronger.\n",
    "- There is a moderate to strong positive relationship with __high income__. This implies that postcode area with high sales prices tend to have a population with higher income.\n",
    "- There is a strong negative relationship with __interest rates__. This is another reasonable observation from an economic point of view. When interest rates decrease, it means capital becomes cheaper i.e. it is easier to get a loan since they are related to the rate level. Hence demand for housing, financed through loans, increases, and prices adjust accordingly.\n",
    "- There is a moderate positive relationship with __construction costs__. This makes sense since house prices should increase as cost for building them increases.\n",
    "- Lastly, there is a strong positive relationship with __sales numbers__. It is not sure at this stage how this actually relates, but the number of sales could be viewed as a proxy for demand which would drive prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa315f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interesting features to analyse over time together with price:\n",
    "- dwelling type (in first EDA notebook)\n",
    "- sales number\n",
    "- median rent\n",
    "- new bonds\n",
    "- bond yields\n",
    "- construction costs\n",
    "- interest rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a882530",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Sales Number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885007c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Median Rent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb7fac",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### New Bonds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c778bff5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Construction Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd62851",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Bond Yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c0cbf2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Interest Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a15d0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### By Postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca74940",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pivot unstacked df to get aggregate values by postcode\n",
    "pivot_postcode = pd.pivot_table(master,\n",
    "                                index=\"postcode\")\n",
    "pivot_postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21747e86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_postcode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f09619",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_postcode = pivot_postcode[['mean_price', 'median_price', 'median_rent_newb', 'new_bonds_no', 'total_bonds_no', '0-4yo', '5-14yo', '15-24yo', '25-34yo', '35-54yo', '55-64yo', '65+yo', 'ATSI', 'CPRF_2', 'CPRF_3', 'CPRF_4','CPRF_5', 'CPRF_6+', 'CPRF_HHOLD_NO', 'CPRF_na', 'INCP_HIGH', 'INCP_LOW', 'INCP_MID', 'INCP_NEG_NIL', 'YARRP 1976-1995', 'YARRP 1996-2005', 'YARRP 2006-2016', 'YARRP <1975', 'citizen_AU', 'citizen_non_AU']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d1018",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show correlation\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "matrix = np.triu(pivot_postcode.corr())\n",
    "\n",
    "sns.heatmap(pivot_postcode.corr(), \n",
    "            annot=True, # put coefficients in\n",
    "            fmt='.2g', # set number of decimals\n",
    "            vmin=-1, vmax=1, center=0, # rescale colorbar\n",
    "            cmap='RdYlGn', # set color palette\n",
    "            square=True, # set squares\n",
    "            mask=matrix) # display only lower triangular matrix\n",
    "plt.yticks(rotation=360)\n",
    "plt.xticks(rotation=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ece5b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Analysis of correlation with price:\n",
    "- There is a very strong positive relationship between the __rent level__ and the sales price level. This implies that postcodes that have high rent prices also tend to have high sales prices. It remains unknown, however, if there actually is a causal relationship.\n",
    "- There is a positive relationship with the amount of __new bonds__. This would make intuitively sense if the number of new bonds is seen as a proxy for demand in an area. First and foremost, this should have an effect on rent levels, but since rent prices are heavily correlated with sales levels, it would make sense if there is some relation with this too.\n",
    "- The number of people in a certain __age bracket__ seems to have a slight positive relationship with sales price for people aged between 25-54. Once could argue that this covers the typical working lifespan and hence people in this age bracket are expected to have more money which is reflected in sales prices.\n",
    "- There is a moderately strong negative relationship with __ATSI__. This implies that prices levels are lower in postcode areas where more people identifying as aboriginal live.\n",
    "- There is a moderate to strong positive relationship with __high income__. This implies that postcode area with high sales prices tend to have a population with higher income.\n",
    "- There is a rather weak positive relationship with the __different years of arrival__ in Australia. At this point, however, it is hard to reason why there should be a relationship\n",
    "- Lastly, there is rather weak positive relationship with __non Australian citizenship__. This implies that postcodes with higher sales prices are culturally more diverse with a larger proportion of non-Australian citizens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09745413",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_postcode.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950efc5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Median Rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78fe010",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"median_rent_newb\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Median Rent and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Median Rent Price\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938c8a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"median_price\", y=\"median_rent_newb\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Median Rent and Median Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Median Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Median Rent Price\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe1df3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Comparing the median sales prices with median rent prices makes intuitively more sense, and also seems to be a more linear relationship. However, for both plots, the relationship looks non-linear and a logarithmic transformation of the median rent level might make sense if we want to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c14ed5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### New Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f68a8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"new_bonds_no\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Number of New Bonds and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of New Bonds\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2602bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_postcode[\"mean_price\"].corr(pivot_postcode[\"new_bonds_no\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea3c71",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a positive relationship. However, the variance is very large. Transformation might help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbff911",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Age Brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca3fea",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"25-34yo\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of 25-34yo Population and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of People between 25-34 Years\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90089623",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"35-54yo\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of 35-54yo Population and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of People between 35-54 Years\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c2dc1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ATSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285bf16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"ATSI\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Aboriginal Heritage and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of People identifying as Aboriginal\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8e9ad",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This looks like a strongly non-linear relationship. Transformation might be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0787d16",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### High Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5354fe1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"INCP_HIGH\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of High Income and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"High Income\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f22f7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There seems to be a somewhat linear relationship with a large variance for larger values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebf28c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Year of Arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753b633",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"YARRP 1996-2005\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Year of Arrival from 1996-2005 and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of People in Year Bracket\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efab1ac",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"YARRP 2006-2016\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of Year of Arrival from 2006-2016 and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of People in Year Bracket\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c350d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Non-AUS Citizen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d68ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.scatterplot(x=\"mean_price\", y=\"citizen_non_AU\", data=pivot_postcode)\n",
    "plt.title(\"Relationship of non-AUS Citizenship and Mean Price Level\", fontsize=14)\n",
    "plt.xlabel(\"Mean Sales Price\", fontsize=12)\n",
    "plt.ylabel(\"Number of non-AUS citizens\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1554c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7b966",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelDF = pd.read_csv(\"Files/Cleaned/Postcode-based/Unstacked_Sales_Rent_5Quarters_Imputed_pcFeatures.csv\",\n",
    "                     index_col=\"postcode\")\n",
    "modelDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb906cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# drop mean price\n",
    "modelDF = modelDF.drop([\"mean_price 2020 Q1\", \"mean_price 2020 Q2\", \"mean_price 2020 Q3\",\n",
    "                        \"mean_price 2020 Q4\", \"mean_price 2021 Q1\"],\n",
    "                      axis=1)\n",
    "modelDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d177c63b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Baseline__ : Predicting from previous quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07481623",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "ypred_base = modelDF['median_price 2020 Q4']\n",
    "r2_score(ypred_base,modelDF['median_price 2021 Q1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc48e1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Baseline Regression Model (Chris)\n",
    "Create a first baseline model here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d630f4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32734400",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Feature Engineering\n",
    "Improve baseline model with different combinations and/or transformation of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a466e9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Improved Model\n",
    "Test if baseline model can be improved by using more sophisticated algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48cfe8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Clustering (Ken & Felix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b07769",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is expected that house prices differ among regions. This is due to different demand activities in different regions. Hence, in the following, clustering will be deployed on the data to use the result for more specific modeling within each cluster that is found to be reasonable. The expectation is a difference between metropolitan and rural areas as it is a global trend that people move to metropolitan areas and Sydney indeed should reflect this with a higher demand than other areas. This expectation will be verified by using the elbow method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8080df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3666a0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "modelDF = pd.read_csv(\"Files/Cleaned/Postcode-based/Unstacked_Transformed.csv\",\n",
    "                     index_col=\"postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2e1d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove interest rate, bond yields (they're the same for all postcodes)\n",
    "modelDF = modelDF.iloc[:, np.r_[0:30, [48], 96:121]] # this is for keeping trans-variables\n",
    "# modelDF = modelDF.iloc[:, np.r_[0:56]] # this is for keeping original variables\n",
    "\n",
    "# Drop mean price columns\n",
    "modelDF = modelDF.drop([\"mean_price 2020 Q1\", \"mean_price 2020 Q2\", \"mean_price 2020 Q3\",\n",
    "                        \"mean_price 2020 Q4\", \"mean_price 2021 Q1\"],axis=1)\n",
    "\n",
    "# Drop one category from each feature group (optional)\n",
    "# modelDF = modelDF.drop(columns=['INCP_NEG_NIL', \n",
    "#                                 '65+yo',\n",
    "#                                 'CPRF_na',\n",
    "#                                 'citizen_AU'],axis=1)\n",
    "\n",
    "print(modelDF.shape)\n",
    "modelDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f034d3b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Scaling the data\n",
    "Since the units differ greatly across the features, scaling will be useful to avoid distorting the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcb765",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For retaining column and index names\n",
    "columns = modelDF.columns\n",
    "postcode = modelDF.index\n",
    "\n",
    "# Initialise scaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Transform\n",
    "scaledDF = scaler.fit_transform(modelDF)\n",
    "\n",
    "# Put into a dataframe\n",
    "scaledDF = pd.DataFrame(scaledDF,index=postcode)\n",
    "scaledDF.columns = columns\n",
    "scaledDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e072c8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Optimal Number of K: Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a8fe3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,11)\n",
    "for i in K:\n",
    "    km = KMeans(n_clusters = i)\n",
    "    km.fit(scaledDF)\n",
    "    distortions.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af2a7d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('$K$')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.xticks(K)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623184ba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This visualisation shows that two clusters seem like a reasonable split to use as the following clusters has less distortion/inertia as the number of clusters grow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0842c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Apply Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b300ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 2, random_state=123)\n",
    "km.fit(scaledDF)\n",
    "km_label_2 = km.predict(scaledDF)\n",
    "modelDF['label_2'] = km_label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c00ff2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelDF.label_2.value_counts(normalize=True).round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6a437",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelDF.groupby('label_2').mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d62bae4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Within these two clusters, Cluster 0 appear to have a significantly higher house prices vs Cluster 1. It also appears that Cluster 0 also has higher proportions of Non-Australian citizens, as well as higher proportions of people who recently arrived to Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee0037",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check the clustering between proportion of high income people and median house price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b79f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=modelDF['median_price 2021 Q1'], y=modelDF['INCP_HIGH_Prop'],\n",
    "            c=modelDF['label_2'],cmap='cividis',alpha=.7)\n",
    "plt.xlabel('Median House Price')\n",
    "plt.ylabel('Proportion of High Income Households')\n",
    "plt.title('2021 Q1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250997f9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax=sns.stripplot(data=modelDF, x='label_2', y='median_price 2021 Q1',hue='INCP_HIGH_Prop',palette='viridis')\n",
    "\n",
    "# Setting up colorbar\n",
    "norm = plt.Normalize(modelDF['INCP_HIGH_Prop'].min(), modelDF['INCP_HIGH_Prop'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm,label='Proportion of High Income')\n",
    "\n",
    "plt.title('Proportion of High Income Bracket Per Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145e1ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cluster 0 which has higher proportions of high income people live in more expensive homes, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ddd17",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Postcodes with median price above \\\\$2.5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ec518",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelDF.loc[modelDF['median_price 2021 Q1']>2500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a33d30",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0335f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load geospatial data\n",
    "lga_gdf = gpd.read_file('Files/Area/LGAs/LGA_2020_AUST.shp') #load the data using Geopandas\n",
    "lga_gdf = lga_gdf[lga_gdf['STE_NAME16']=='New South Wales'] #Select the data for the state of NSW\n",
    "lga_gdf['LGA_CODE20'] = lga_gdf['LGA_CODE20'].astype('str') # we will join on this axis, so both dataframes need this to be the same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302decba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lga_gdf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7318fa6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in NSW postcode long-lat file\n",
    "postcode_gdf = pd.read_csv('Files/Area/au_postcodes.csv')\n",
    "nsw = postcode_gdf[postcode_gdf.state_code=='NSW'] #filter to NSW\n",
    "nsw = pd.pivot_table(nsw, index='postcode', values=['latitude','longitude'], aggfunc='mean')\n",
    "\n",
    "# make geometry for point\n",
    "nsw = gpd.GeoDataFrame(\n",
    "    nsw, geometry=gpd.points_from_xy(nsw.longitude, nsw.latitude)) \n",
    "nsw = nsw[['geometry']]\n",
    "nsw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca53636",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cluster = modelDF[['label_2']] # Get KMeans cluster label only\n",
    "df_cluster.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eaf95",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "map_kmeans_label = pd.merge(nsw, df_cluster, on='postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce8532",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(30,30))\n",
    "divider = make_axes_locatable(ax)\n",
    "lga_gdf.plot(ax=ax, color='gray',alpha=.8) # Map data\n",
    "lga_gdf.geometry.boundary.plot(color='white', ax=ax, linewidth=0.1) #Add some borders to the geometries\n",
    "\n",
    "# Zoom in\n",
    "minx, miny, maxx, maxy = lga_gdf.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "\n",
    "map_kmeans_label.plot(column='label_2',ax=ax,cmap='cividis',alpha=1, categorical=True, legend=True)\n",
    "ax.axis('off')\n",
    "plt.title('KMeans Clusters (2), NSW',fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269ae6f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One cluster are situated mostly near Sydney. Interestingly however, there are some postcodes outside Sydney also classified as similar to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c612d9a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6412d8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the following, it will be checked whether results appear to be more reasonable when applying agglomerative clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119bcc16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "modelDF = pd.read_csv(\"Files/Cleaned/Postcode-based/Unstacked_Transformed.csv\",\n",
    "                     index_col=\"postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64c397",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove interest rate, bond yields (they're the same for all postcodes)\n",
    "modelDF = modelDF.iloc[:, np.r_[0:30, [48], 96:121]] # this is for keeping trans-variables\n",
    "# modelDF = modelDF.iloc[:, np.r_[0:56]] # this is for keeping original variables\n",
    "\n",
    "# Drop mean price columns\n",
    "modelDF = modelDF.drop([\"mean_price 2020 Q1\", \"mean_price 2020 Q2\", \"mean_price 2020 Q3\",\n",
    "                        \"mean_price 2020 Q4\", \"mean_price 2021 Q1\"],axis=1)\n",
    "\n",
    "# Drop one category from each feature group (optional)\n",
    "# modelDF = modelDF.drop(columns=['INCP_NEG_NIL', \n",
    "#                                 '65+yo',\n",
    "#                                 'CPRF_na',\n",
    "#                                 'citizen_AU'],axis=1)\n",
    "\n",
    "print(modelDF.shape)\n",
    "modelDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50976d5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1340da3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The same scaling procedure will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc41628",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for retaining column and index names\n",
    "columns = modelDF.columns\n",
    "postcode = modelDF.index\n",
    "\n",
    "# Initialise scaler\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Transform\n",
    "scaledDF = scaler.fit_transform(modelDF)\n",
    "\n",
    "# Put into a dataframe\n",
    "scaledDF = pd.DataFrame(scaledDF,index=postcode)\n",
    "scaledDF.columns = columns\n",
    "scaledDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aebbb0d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Apply algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b6dee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# linkage\n",
    "plt.figure(figsize=(14,10))\n",
    "mergings = linkage(scaledDF, method=\"ward\", metric='euclidean')\n",
    "dendrogram(mergings, orientation='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ad767",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hier_labels = cut_tree(mergings,n_clusters=3)\n",
    "modelDF['labels'] = hier_labels\n",
    "modelDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c229c0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check distribution of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae47a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelDF.labels.value_counts(normalize=True).round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e759e0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "modelDF.groupby('labels').mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b96086",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=modelDF['median_price 2021 Q1'], y=modelDF['INCP_HIGH_Prop'],\n",
    "            c=modelDF['labels'],cmap='cividis',alpha=.6)\n",
    "plt.xlabel('Median House Price')\n",
    "plt.ylabel('Proportion of High Income Households')\n",
    "plt.title('2021 Q1, Hierarchical clustering');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08d30cb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd2f45",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_hier_cluster = modelDF['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a9f5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "map_hier_label = pd.merge(nsw, df_hier_cluster, on='postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0857a5",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(30,30))\n",
    "divider = make_axes_locatable(ax)\n",
    "lga_gdf.plot(ax=ax, color='gray',alpha=1) # Map plot\n",
    "lga_gdf.geometry.boundary.plot(color='white', ax=ax, linewidth=0.2) #Add some borders to the geometries\n",
    "\n",
    "# Zoom in\n",
    "minx, miny, maxx, maxy = lga_gdf.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "\n",
    "map_hier_label.plot(column='labels',ax=ax,cmap='viridis',alpha=1, categorical=True, legend=True)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title('Hierarchical Clustering (3), NSW',fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e2165",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is interesting that some of the postcodes in the northern-eastern most part of NSW are being classified as similar to Sydney."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008be9d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b241d30d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While the clusters on hierarchical clusters might make sense, it can be difficult to use this for prediction due to the small sample size on one of the clusters. Thus, KMeans clusters will be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed3d54",
   "metadata": {},
   "source": [
    "# Distinct Models per Clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d80dbbe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Linear regression based on KMeans clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad69ed",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecdc58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "modelDF = pd.read_csv(\"Files/Cleaned/Postcode-based/Unstacked_Transformed.csv\",\n",
    "                     index_col=\"postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c171ff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove interest rate, bond yields (they're the same for all postcodes)\n",
    "modelDF = modelDF.iloc[:, np.r_[0:30, [48], 96:121]] # this is for keeping trans-variables\n",
    "# modelDF = modelDF.iloc[:, np.r_[0:56]] # this is for keeping original variables\n",
    "\n",
    "# Drop mean price columns\n",
    "modelDF = modelDF.drop([\"mean_price 2020 Q1\", \"mean_price 2020 Q2\", \"mean_price 2020 Q3\",\n",
    "                        \"mean_price 2020 Q4\", \"mean_price 2021 Q1\"],axis=1)\n",
    "\n",
    "# Drop one category from each feature group (optional)\n",
    "# modelDF = modelDF.drop(columns=['INCP_NEG_NIL', \n",
    "#                                 '65+yo',\n",
    "#                                 'CPRF_na',\n",
    "#                                 'citizen_AU'],axis=1)\n",
    "\n",
    "print(modelDF.shape)\n",
    "modelDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741bf562",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using labels from KMeans where k=2\n",
    "modelDF['labels'] = km_label_2\n",
    "modelDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96282de",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Sub-setting clusters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04c32f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cluster0 = modelDF.loc[modelDF['labels']==0]\n",
    "cluster1 = modelDF.loc[modelDF['labels']==1]\n",
    "\n",
    "cluster0 = cluster0.drop('labels',axis=1)\n",
    "cluster1 = cluster1.drop('labels',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22541d47",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model on the 2 Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27921d0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 1st cluster\n",
    "lr = LinearRegression()\n",
    "scoreKM0 = cross_val_score(lr, cluster0.drop(['median_price 2021 Q1'],axis=1), # X\n",
    "                        cluster0['median_price 2021 Q1'],                      # y \n",
    "                        cv=KFold(n_splits=5, shuffle=True, random_state=42)) \n",
    "print('R2 on 1st cluster:',list(scoreKM0.round(4)), '| Mean:', scoreKM0.mean().round(4))\n",
    "\n",
    "# 2nd cluster\n",
    "lr = LinearRegression()\n",
    "scoreKM1 = cross_val_score(lr, cluster1.drop(['median_price 2021 Q1'],axis=1), # X\n",
    "                        cluster1['median_price 2021 Q1'],                      # y \n",
    "                        cv=KFold(n_splits=5, shuffle=True, random_state=42))\n",
    "print('R2 on 2nd cluster:',list(scoreKM1.round(4)), '| Mean:', scoreKM1.mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5490e1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot $R^2$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f9a73",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "splits = range(1,6)\n",
    "plt.plot(splits, scoreKM0,label='Cluster 1')\n",
    "plt.plot(splits, scoreKM1,label='Cluster 2')\n",
    "plt.title('R2 scores')\n",
    "plt.xlabel('Trial #')\n",
    "plt.xticks(splits)\n",
    "plt.ylabel('$R^2$')\n",
    "plt.ylim(0,1)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c114f6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Hyperparameter Tuning Using Grid Search Cross-Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee533363",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cluster 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a51526",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea615728",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = cluster0.drop(['median_price 2021 Q1'],axis=1)\n",
    "y = cluster0['median_price 2021 Q1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=123, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c7179",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 51))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bff6f2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e38bc67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.set_theme()\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.xticks(range(0,51,2))\n",
    "plt.ylabel('$R^2$')\n",
    "plt.title(\"Optimal Number of Features, Cluster 0\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669e769",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It appears that the optimal number of features on cluster 0 is at 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158fd40",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_features_optimal = 42\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lr, n_features_to_select = n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# predict prices of X_test\n",
    "y_pred = rfe.predict(X_test)\n",
    "\n",
    "# check r2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Train R2 for linear regression on cluster 0: {r2_score(y_train,rfe.predict(X_train)).round(4)}') \n",
    "print(f'Test R2 for linear regression on cluster 0: {r2.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ed763f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cross-validated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e1878",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cluster 0\n",
    "print('Cross-validated R2 score on cluster 0:')\n",
    "cross_val_score(rfe, cluster0.drop(['median_price 2021 Q1'],axis=1), # X\n",
    "                        cluster0['median_price 2021 Q1'],            # y \n",
    "                        cv=KFold(n_splits=5, shuffle=True, random_state=42)).mean().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26dec97",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaed4fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = cluster1.drop(['median_price 2021 Q1'],axis=1)\n",
    "y = cluster1['median_price 2021 Q1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=100, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55eb419",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = KFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 51))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr)             \n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe, \n",
    "                        param_grid = hyper_params, \n",
    "                        scoring= 'r2', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468ddfe",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8913d8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.xticks(range(0,51,2))\n",
    "plt.title(\"Optimal Number of Features, Cluster 1\")\n",
    "plt.legend(['test score', 'train score'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9dd3bb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The optimal number of features in cluster 1 seems to be at 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17af41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_features_optimal = 36\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(lr, n_features_to_select = n_features_optimal)             \n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# predict prices of X_test\n",
    "y_pred = rfe.predict(X_test)\n",
    "\n",
    "# check r2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Train R2 for linear regression on cluster 1: {r2_score(y_train,rfe.predict(X_train)).round(4)}') \n",
    "print(f'Test R2 for linear regression on cluster 1: {r2.round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52201c0d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cross-validated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9053b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cluster 1\n",
    "print('Cross-validated R2 score on cluster 1:')\n",
    "cross_val_score(rfe, cluster1.drop(['median_price 2021 Q1'],axis=1), # X\n",
    "                        cluster1['median_price 2021 Q1'],            # y \n",
    "                        cv=KFold(n_splits=5, shuffle=True, random_state=42)).mean().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c8868",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710458cf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using linear regression on the individual KMeans clusters, the models seem to overfit and does not perform very well, especially on cluster 1.\n",
    "\n",
    "For predicting median house prices, it may be better to utilise the whole NSW postcodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4f5c70",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Aside from predicting the house price, we're curious to see if we can predict the postcodes that will grow more than 5% on the following quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "modelDF = pd.read_csv(\"Files/Cleaned/Postcode-based/Unstacked_Transformed.csv\",\n",
    "                     index_col=\"postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove interest rate, bond yields (they're the same for all postcodes)\n",
    "modelDF = modelDF.iloc[:, np.r_[0:30, [48], 96:121]] # this is for keeping trans-variables\n",
    "# modelDF = modelDF.iloc[:, np.r_[0:56]] # this is for keeping original variables\n",
    "\n",
    "# Drop mean price columns\n",
    "modelDF = modelDF.drop([\"mean_price 2020 Q1\", \"mean_price 2020 Q2\", \"mean_price 2020 Q3\",\n",
    "                        \"mean_price 2020 Q4\", \"mean_price 2021 Q1\"],axis=1)\n",
    "\n",
    "# Drop one category from each feature group\n",
    "modelDF = modelDF.drop(columns=['INCP_NEG_NIL_Prop', \n",
    "                                 '65+yo_Prop',\n",
    "                                 'CPRF_na_Prop',\n",
    "                                 'citizen_AU_Prop'],axis=1)\n",
    "\n",
    "print(modelDF.shape)\n",
    "pd.set_option('display.max_columns', None)\n",
    "modelDF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4384c3",
   "metadata": {},
   "source": [
    "## Assign class label - define 'high growth potential' areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99412121",
   "metadata": {},
   "source": [
    "Calculate growth rate of median house price for each quarter to draw the line of high/low growth potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eae0da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Growth rate Q1-Q2 2020\n",
    "modelDF['gr_20Q2'] = ((modelDF['median_price 2020 Q2']/modelDF['median_price 2020 Q1'])-1)*100\n",
    "\n",
    "# Growth rate Q2-Q3 2020\n",
    "modelDF['gr_20Q3'] = ((modelDF['median_price 2020 Q3']/modelDF['median_price 2020 Q2'])-1)*100\n",
    "\n",
    "# Growth rate Q3-Q4 2020\n",
    "modelDF['gr_20Q4'] = ((modelDF['median_price 2020 Q4']/modelDF['median_price 2020 Q3'])-1)*100\n",
    "\n",
    "# Growth rate Q4 2020 - Q1 2020\n",
    "modelDF['gr_21Q1'] = ((modelDF['median_price 2021 Q1']/modelDF['median_price 2020 Q4'])-1)*100\n",
    "\n",
    "# Annual growth rate Q1 2020 - Q1 2021\n",
    "modelDF['gr_annual'] = ((modelDF['median_price 2021 Q1']/modelDF['median_price 2020 Q1'])-1)*100\n",
    "\n",
    "modelDF.iloc[:,47:52].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed4dd1b",
   "metadata": {},
   "source": [
    "As we can see from the above summary table, the range of house price changes is fairly large. In certain area, the median price increased 6 folds in Q1 2021. However, it would be irrational to only consider such dramatic increase as 'high growth'. \n",
    "\n",
    "The **mean** and **50% (median)** of growth rates would give us a better idea of the general trends in the market - we could see the growth started to accelerate in Q4 last year and continued to hold strong in 2021 with an average of **6.81%** and a median of **3.75%**. And due to the extreme cases on the higher ends, average is always more 'inflated' than median for all four time periods.\n",
    "\n",
    "Hence, we'd like to set the threshold **between the mean and median growth rate of the last known period (Q1 2021) at 5%**, classify postcodes whose median price increasing by greater than or equal 5% as **'high growth'** and those less than 5% as 'low growth' areas, and build a classifier to predict the growth potential (binary class) of each postcode in the future time period.\n",
    "\n",
    "We will create a class variable `high_growth`, and assign label 1 or 0 to each row based on the previously calculated `gr_21Q1` according to above stated rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbefe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class variable and assign class label\n",
    "modelDF['high_growth'] = np.where(modelDF.gr_21Q1 >= 5,'1','0')\n",
    "\n",
    "print('Percentage of high growth and low growth areas:')\n",
    "pd.DataFrame(modelDF['high_growth'].value_counts(normalize=True).round(3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea86da",
   "metadata": {},
   "source": [
    "In our book, 41% of postal areas are considered 'high growth' areas and 59% 'low growth' areas. \n",
    "\n",
    "This **59%** is considered our **'chance accuracy'**, i.e., without learning, our model would simply classify all cases into 'low growth', the majority class, and have an accuracy of 59%, which will serve as the baseline for the classifiers we buil in later sections. Ideally, we should expect greater accuracy than 59% (the greater the better!) from our trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf8d13e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51463124",
   "metadata": {},
   "source": [
    "###  Base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b202931",
   "metadata": {},
   "source": [
    "Use __Random Forect Classifier__ and train_test_split to check the accuracy score for predicting if a postcode grew more than the mean growth rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X = modelDF.drop(['median_price 2021 Q1', 'high_growth','gr_annual','gr_21Q1'],axis=1)\n",
    "y = modelDF['high_growth']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , random_state=123, test_size=.2, \n",
    "                                                    stratify = modelDF['high_growth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with Random Forest\n",
    "rfc = RandomForestClassifier(random_state=123)\n",
    "rfc.fit(X_train,y_train)\n",
    "ypredRFC = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bac611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model diagnostics\n",
    "print('Accuracy score on test data:',accuracy_score(ypredRFC, y_test).round(4)*100,'%') #Accuracy\n",
    "\n",
    "cm_rf1 = confusion_matrix(y_test, ypredRFC)\n",
    "rec_rf1 = 100*cm_rf1[1][1] / (cm_rf1[1][1] + cm_rf1[1][0])\n",
    "prec_rf1 = 100*cm_rf1[1][1] / (cm_rf1[1][1] + cm_rf1[0][1])\n",
    "\n",
    "print('Recall of the random forest classifier: %.2f' % rec_rf1,'%')\n",
    "print('Precision of the random forest classifier: %.2f' % prec_rf1,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b70d59",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca05f05",
   "metadata": {},
   "source": [
    "Use cross-validation to test the data thoroughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c81eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=123)\n",
    "scoreRFC = cross_val_score(rfc, X, y, scoring='accuracy',\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "print('Using cross-validation\\nAverage accuracy is:',scoreRFC.mean().round(4)*100,'%')\n",
    "print('STDEV:',scoreRFC.std().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = cross_val_predict(rfc, X, y, \n",
    "                              cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "cm_rf2 = confusion_matrix(y, y_pred_cv)\n",
    "rec_rf2 = 100*cm_rf2[1][1] / (cm_rf2[1][1] + cm_rf2[1][0])\n",
    "prec_rf2 = 100*cm_rf2[1][1] / (cm_rf2[1][1] + cm_rf2[0][1])\n",
    "\n",
    "print('Recall of the random forest classifier (validated): %.2f' % rec_rf2,'%')\n",
    "print('Precision of the random forest classifier (validated): %.2f' % prec_rf2,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409ce4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm_rf2/cm_rf2.astype(float).sum(axis=1), \n",
    "                 annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee07cee",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803dd54",
   "metadata": {},
   "source": [
    "Set up the parameters to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ceea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [2,4,6,8,None],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=parameters, cv=folds, n_jobs=-1)\n",
    "CV_rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f0171",
   "metadata": {},
   "source": [
    "See which are the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit model with the selected best parameters\n",
    "\n",
    "print(CV_rfc.best_params_)\n",
    "rfc_best = RandomForestClassifier(random_state=123)\n",
    "rfc_best.set_params(**CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Accuracy score\n",
    "\n",
    "scoreRFC2 = cross_val_score(rfc_best, X, y,\n",
    "                           scoring='accuracy',\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "print('Using cross-validation\\nTuned average accuracy is:',scoreRFC2.mean().round(4)*100,'%')\n",
    "print('STDEV:',scoreRFC.std().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f217e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(rfc_best, X, y, \n",
    "                              cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "cm_rf3 = confusion_matrix(y, y_pred)\n",
    "rec_rf3 = 100*cm_rf3[1][1] / (cm_rf3[1][1] + cm_rf3[1][0])\n",
    "prec_rf3 = 100*cm_rf3[1][1] / (cm_rf3[1][1] + cm_rf3[0][1])\n",
    "\n",
    "print('Recall of the tuned random forest classifier: %.2f' % rec_rf3,'%')\n",
    "print('Precision of tuned the random forest classifier: %.2f' % prec_rf3,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf560c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm_rf3/cm_rf3.astype(float).sum(axis=1), \n",
    "                 annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7a97a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8634b2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Illustration of one of the trees in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59eece",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rfc_best.fit(X,y)\n",
    "estimator = rfc_best.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2b170",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "tree.plot_tree(estimator, max_depth=4, filled=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea43dd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056908c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get Class Labels\n",
    "df_rfc = modelDF['high_growth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500f554",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Merge labels to map data\n",
    "map_rfc = pd.merge(nsw, df_rfc, on='postcode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981804b",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(30,30))\n",
    "divider = make_axes_locatable(ax)\n",
    "lga_gdf.plot(ax=ax, color='gray',alpha=.2) # Map plot\n",
    "lga_gdf.geometry.boundary.plot(color='gray', ax=ax, linewidth=0.2) #Add some borders to the geometries\n",
    "\n",
    "# Zoom in\n",
    "minx, miny, maxx, maxy = lga_gdf.total_bounds\n",
    "ax.set_xlim(minx, maxx)\n",
    "ax.set_ylim(miny, maxy)\n",
    "\n",
    "map_rfc.plot(column='high_growth',ax=ax,cmap='YlGn', categorical=True, legend=True)\n",
    "ax.axis('off')\n",
    "plt.title('Postcodes predicted to grow >5%, NSW',fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313b732",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd2b7e",
   "metadata": {},
   "source": [
    "The cross-validation score result from the tuned random forest classifier model performs slightly better compared to the default model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b087702",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bf0fb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on neural network, the MLP Classifier is another great candidate for discovering existing patterns in data and extrapolating them, although it's sometimes considered most useful when input variables are categorical. Regardless, we are keen to try it on our numeric inputs and see how it compares with the random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e922a5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Base model\n",
    "\n",
    "First build a baseline MPLClassifier using default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd171f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Specify features and the target\n",
    "X = modelDF.drop(['median_price 2021 Q1', 'high_growth', 'gr_annual','gr_21Q1'], axis=1)\n",
    "y = modelDF['high_growth']\n",
    "\n",
    "# Split the dataset into training data and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=123,\n",
    "                                                   stratify = modelDF['high_growth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd56056",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Training the MLPClassifier with the default parameters (random_state=42)\n",
    "mlpc = MLPClassifier(random_state=44)\n",
    "mlpc.fit(X_train, y_train)\n",
    "\n",
    "# Output the accuracy on training data and test data respectively\n",
    "y_pred_train = mlpc.predict(X_train)\n",
    "y_pred_test = mlpc.predict(X_test)\n",
    "\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print('Train Accuracy for the default MLP classifier: %.4f' % acc_train)\n",
    "print('Test Accuracy for the default MLP classifier: %.4f' % acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7e7b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Output the confusion matrix on test data\n",
    "\n",
    "cm_mlp1 = confusion_matrix(y_test, y_pred_test)\n",
    "rec_mlp1 = 100*cm_mlp1[1][1] / (cm_mlp1[1][1] + cm_mlp1[1][0])\n",
    "prec_mlp1 = 100*cm_mlp1[1][1] / (cm_mlp1[1][1] + cm_mlp1[0][1])\n",
    "\n",
    "print('Recall of the default MLP classifier: %.2f' % rec_mlp1,'%')\n",
    "print('Precision of the default MLP classifier: %.2f' % prec_mlp1,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a6cb4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The good news is the accuracy (**75.11%**) of the baseline MLP classifier is greater than 59%, the chance accuracy withtou tuning, however we observe a gap in train/test accuracy, suggesting potential overfitting - something to bear in mind in later validation and tuning.\n",
    "\n",
    "Recall seems to be incredibly high (91.49%), which is likely to be due to the random seed. We'll rule this out using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916eca6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Explore the learned MLP model\n",
    "print(mlpc)\n",
    "print('\\n# of layers (including the input layer): %.f' % mlpc.n_layers_)\n",
    "print('MLP structure: %.f X %.f X %.f' % (X.shape[1], \n",
    "                                          mlpc.get_params()['hidden_layer_sizes'][0], \n",
    "                                          mlpc.n_outputs_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01884c7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our current model has 1 hidden layers, 100 units per hidden layer - in later tuning, we might experiment with less number of hidden layers and/or less number of perceptrons per layer, and see if a simpler model will have more consistent performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c0c770",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Cross Validation\n",
    "Use 10-fold cross validation to report a more robust testing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a03ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use 5-fold cross validation to validate the model\n",
    "scores_mlp_default = cross_val_score(mlpc, X, y, \n",
    "                                     cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "\n",
    "print('Accuracy range for the default MLP classifier: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores_mlp_default.min(), \n",
    "         scores_mlp_default.max(), \n",
    "         scores_mlp_default.mean(), \n",
    "         scores_mlp_default.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc959ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check confusion matrix\n",
    "y_pred_2 = cross_val_predict(mlpc, X, y,\n",
    "                           cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "\n",
    "cm_mlp2 = confusion_matrix(y, y_pred_2)\n",
    "rec_mlp2 = 100*cm_mlp2[1][1] / (cm_mlp2[1][1] + cm_mlp2[1][0])\n",
    "prec_mlp2 = 100*cm_mlp2[1][1] / (cm_mlp2[1][1] + cm_mlp2[0][1])\n",
    "\n",
    "print('Recall of the default MLP classifier (validated): %.2f' % rec_mlp2,'%')\n",
    "print('Precision of the default MLP classifier (validated): %.2f' % prec_mlp2,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abee48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm_mlp2/cm_mlp2.astype(float).sum(axis=1), \n",
    "                 annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac7215",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It turns out that our concern for the low recall might have been a false alarm! \n",
    "\n",
    "The 10-fold cross validation shows that our default model has an avarage accuracy of **69.10%**, about 10 pts higher than the chance accuracy of 59%, **66.38%** correct recall and **61.42%** precision. That's certainly not a bad baseline model to start with. But can we make it better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ee8c6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "We will be using two different tuning method and explore which yields a better model: \n",
    "1. Tune each parameter <u>individually</u>, build a final classifier with the optimal value of each individual parameter found;\n",
    "2. Use `GridSearchCV` to find the optimal combination of parameters of all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53def7f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Tuning Individual Parameter\n",
    "\n",
    "**<u>a. Number of hidden units</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb524977",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The default number of hidden units is 100. With 51 input units and 2 output classes, our default model has (51+1)x100 + (100+1)x2 = **5402** model parameters (weights), which is relatively large compared to our sample size (n=573). This may impact the consistency of our model and create potential issue of overfitting.\n",
    "\n",
    "Here're going to test a range of numbers of hidden units, moving in both direction from 100, and use 10-fold cross validation to report on the testing accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74d811",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For each number of hidden units, we use 10-fold cross validation to report the testing accuracy.\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "\n",
    "hidden_units_no = [[10],[25],[50],[75],[100],[125],[150]]\n",
    "\n",
    "for i in hidden_units_no:\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=i, random_state=44)\n",
    "    scores = cross_val_score(mlpc, X, y, scoring='accuracy', \n",
    "                             cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ec2bd",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy against the number of hidden units\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.errorbar(hidden_units_no, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "\n",
    "plt.xlabel('Number of hidden units')\n",
    "plt.xticks(np.arange(0, 151, 25))\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.2, 0.8)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a9fa8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Find the optimal number of hidden units\n",
    "tuned_score = max(cv_scores)\n",
    "max_index = cv_scores.index(tuned_score)\n",
    "tuned_hlsizes = hidden_units_no[max_index][0]\n",
    "\n",
    "print(\"Best accuracy score: %.4f\" % tuned_score)\n",
    "print(\"Optimal number of hidden units:\", tuned_hlsizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fca57",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From above graph and calculation, we could see that the number of hidden units per layer to **n=10** gives us the best overall accuracy, which confirms our hypothesis.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc76e8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**<u>b. Number of hidden layers</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e8faf4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we suspected the complexity of the model would cause overfitting, we're dubious that adding the number of hidden layers would improve accuracy. So here we're only going to try 2 hidden layers and go back to our simple 1-layer model if there's no significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38327e4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try a MLP model with two hidden layers, 100 units each (default)\n",
    "mplc = MLPClassifier (hidden_layer_sizes=[100,100], random_state=44)\n",
    "\n",
    "scores = cross_val_score(mlpc, X, y, scoring='accuracy', \n",
    "                         cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123), \n",
    "                         verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bff49e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy for the 2-layer MLP classifier: mean: %.4f; std: %.4f\\n'\n",
    "      % (scores.mean(), \n",
    "         scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431395b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recall that the average accuracy for the default MLP classifier with 1 hidden layer of 100 units is **69.10%**. It seems though adding 1 more layer doesn't give us much edge at all. Regardless, we'll do our due diligence and perform a T-test for significant changes.\n",
    "\n",
    "$ H_0 $ = 1 hidden layer performs similarly to 2 hidden layers  \\\n",
    "$ H_1 $ = 1 hidden layer performance is different from 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf5660",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Peform T-test to determine if there's significant improvement in scores\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "print(\"T-test results:\", ttest_ind(scores_mlp_default, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ab1bc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since **p-value 0.77** is much greater than the significance levels of 10%, we fail to reject the null that results from the two models are statistically different from one another and conclude that they perform similarly. As such, we will **just stick to 1 hidden layer**.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f32366",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**<u>c. Choose the solver</u>**\n",
    "\n",
    "Test which solver (`lbfgs`,`sgd`, `adam`) performs the best with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fecd0b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try different solvers - lbfgs can't converge?\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "solvers = ['lbfgs','sgd', 'adam']\n",
    "for i in solvers:\n",
    "    mlpc = MLPClassifier(solver=i, random_state=44)\n",
    "    scores = cross_val_score(mlpc, X, y, scoring='accuracy', \n",
    "                             cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a6f16",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.bar(solvers, cv_scores, yerr=cv_scores_std, label='Accuracy')\n",
    "plt.xlabel('Solvers')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.2, 1)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c80120",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the optimal solver for later use\n",
    "tuned_score = max(cv_scores)\n",
    "tuned_solver = (solvers[cv_scores.index(tuned_score)])\n",
    "\n",
    "print(\"Best accuracy score: %.4f\" % tuned_score)\n",
    "print(\"Best solver:\", tuned_solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1add84db",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is obvious that `adam`, the default solver, outperforms lbfgs and sgd and will be the preferred solver to bring along to the final model\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941efb76",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**<u>d. Choose the activation Function</u>**\n",
    "\n",
    "Activation function also plays a critical role in neural-network-based classifier, and we have a list to shop from: `identity`,`logistic`, `tanh` and `relu`, whic is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacc032",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try different activation functions\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "activations = ['identity','logistic','tanh','relu']\n",
    "\n",
    "for a in activations:\n",
    "    mlpc = MLPClassifier(activation=a, random_state=44)\n",
    "    scores = cross_val_score(mlpc, X, y, scoring='accuracy', \n",
    "                             cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597125bd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy against activation fuction\n",
    "plt.bar(activations, cv_scores, yerr=cv_scores_std, label='Accuracy')\n",
    "plt.xlabel('Activation Functions')\n",
    "plt.ylim([0.2, 1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367830ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the optimal activation function for later use\n",
    "tuned_score = max(cv_scores)\n",
    "tuned_act = (activations[cv_scores.index(tuned_score)])\n",
    "\n",
    "print(\"Best accuracy score: %.4f\" % tuned_score)\n",
    "print(\"Best activatioin function:\", tuned_act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd504e4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The morale of the story so far is that simple is best - `relu`, the default activation function also outperforms all three alternatives and will be the favourable. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e921ce",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**<u>e. L2 Regularisation</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646df05",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Alpha is the parameter for regularisation term, which penalises the number of weights as it increases and thereby deals with overfitting. The greater the alpha value, the heavier the penalty We'll be testing a range of alpha (0.0001,0.001,0.01, 0.1,1) and see if any provides improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50325f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try different regularisation parameters\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "alphas = [0.0001,0.001,0.01, 0.1, 1]\n",
    "for i in alphas:\n",
    "    mplc = MLPClassifier(alpha=i,random_state=44)\n",
    "    scores = cross_val_score(mplc, X, y, scoring='accuracy', \n",
    "                             cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9516762",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy against alpha values\n",
    "plt.errorbar(alphas, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylim([0.4, 0.9])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9284ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the optimal alpha for later use\n",
    "tuned_score = max(cv_scores)\n",
    "tuned_alpha = (alphas[cv_scores.index(tuned_score)])\n",
    "\n",
    "print(\"Best accuracy score: %.4f\" % tuned_score)\n",
    "print(\"Best alpha value:\", tuned_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78a758",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The average accuracy peaked when **alpha=1**. A very heavy complexity penalty seems to be in favour, which is logical yet again given the size of our data.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed52f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**<u>f. Number of iterations</u>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21152f5f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Try different number of iterations\n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "iterations = [100, 200, 400, 600, 800]\n",
    "for i in iterations:\n",
    "    mlpc = MLPClassifier(max_iter=i, random_state=44)\n",
    "    scores = cross_val_score(mlpc, X, y, scoring='accuracy', \n",
    "                             cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123))\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea3082",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the relationship\n",
    "plt.errorbar(iterations, cv_scores, yerr=cv_scores_std, marker='x', label='Accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.4,0.8)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd2399",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The number of iterations do not seem to improve the model, however we've encoutered the problem where max iteration is reached but the model hasn't converged yet. Hence in the final model, we may want to bump up max iteration a bit just to help the model converge to the optimised result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cafd2f9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Tuning with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50b7e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# GridSearch\n",
    "mlp = MLPClassifier(random_state=123)\n",
    "\n",
    "parameters = { \n",
    "    'hidden_layer_sizes': [[10],[25],[50],[75],[100],[150]],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'activation':['identity','logistic','tanh','relu'],\n",
    "    'alpha' : [0.0001,0.01,0.1,1],\n",
    "    'max_iter' :[100, 200, 400]\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "gs_mlp = GridSearchCV(estimator=mlp, param_grid=parameters, cv=folds, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db337c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs_mlp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065fa8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(gs_mlp.best_params_)\n",
    "\n",
    "gs_act = gs_mlp.best_params_['activation']\n",
    "gs_alpha = gs_mlp.best_params_['alpha']\n",
    "gs_hlsizes = gs_mlp.best_params_['hidden_layer_sizes']\n",
    "gs_solver = gs_mlp.best_params_['solver']\n",
    "gs_iter = gs_mlp.best_params_['max_iter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ef651",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Best MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d5a18",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Best MLPClassifier - based on individual tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7944441",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Best MLP classifier based on individual tuning\n",
    "\n",
    "mlp_best1 = MLPClassifier(hidden_layer_sizes=[tuned_hlsizes],\n",
    "                          solver=tuned_solver,\n",
    "                          activation=tuned_act,\n",
    "                          alpha=tuned_alpha,\n",
    "                          random_state=44, \n",
    "                          max_iter=500) #increase max_iter to 500 for convergence\n",
    "\n",
    "scores_mlp_best1 = cross_val_score(mlp_best1, X, y, \n",
    "                                  cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123), \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acc2d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for the best MLP:\", \"{:.4f}\".format(scores_mlp_best1.mean()), \n",
    "      \"STD:\", \"{:.4f}\".format(scores_mlp_best1.std()))\n",
    "\n",
    "\n",
    "y_pred_3 = cross_val_predict(mlp_best1, X, y,\n",
    "                             cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "cm_mlp3 = confusion_matrix(y, y_pred_3)\n",
    "rec_mlp3 = 100*cm_mlp3[1][1] / (cm_mlp3[1][1] + cm_mlp3[1][0])\n",
    "prec_mlp3 = 100*cm_mlp3[1][1] / (cm_mlp3[1][1] + cm_mlp3[0][1])\n",
    "\n",
    "print('Recall of the tuned random forest classifier: %.2f' % rec_mlp3,'%')\n",
    "print('Precision of tuned the random forest classifier: %.2f' % prec_mlp3,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65627d8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm_mlp3/cm_mlp3.astype(float).sum(axis=1), \n",
    "                 annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd808cd6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Best MLPClassifier - based on GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ae319",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Best MLP classifier based on GS\n",
    "\n",
    "mlp_best2 = MLPClassifier(hidden_layer_sizes=gs_hlsizes,\n",
    "                         solver=gs_solver,\n",
    "                         activation=gs_act,\n",
    "                         alpha=gs_alpha,\n",
    "                          max_iter=gs_iter,\n",
    "                         random_state=44)\n",
    "scores_mlp_best2 = cross_val_score(mlp_best2, X, y, \n",
    "                                  cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=123), \n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff19e08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy for the best MLP:\", \"{:.4f}\".format(scores_mlp_best2.mean()), \n",
    "      \"STD:\", \"{:.4f}\".format(scores_mlp_best2.std()))\n",
    "\n",
    "y_pred_4 = cross_val_predict(mlp_best2, X, y,\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123))\n",
    "\n",
    "cm_mlp4 = confusion_matrix(y, y_pred_4)\n",
    "rec_mlp4 = 100*cm_mlp4[1][1] / (cm_mlp4[1][1] + cm_mlp4[1][0])\n",
    "prec_mlp4 = 100*cm_mlp4[1][1] / (cm_mlp4[1][1] + cm_mlp4[0][1])\n",
    "\n",
    "print('Recall of the tuned random forest classifier: %.2f' % rec_mlp4,'%')\n",
    "print('Precision of tuned the random forest classifier: %.2f' % prec_mlp4,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dad4b0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(cm_mlp4/cm_mlp4.astype(float).sum(axis=1), \n",
    "                 annot=True, fmt=\".2%\", linewidths=.5, square = True, cmap = 'Blues')\n",
    "\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_ticklabels(['0', '1'])\n",
    "ax.yaxis.set_ticklabels(['0', '1'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab22fa5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Conclusion__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cb016",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Result is better than just guessing which postcodes will increase more than 5%.  \n",
    "\n",
    "However, there might be other data that can help increase the accuracy score, such as:\n",
    "- Employment rate per postcode\n",
    "- Whether there are parks nearby\n",
    "- Possibly many more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ba865",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db9e4a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Conclusion and Outlook\n",
    "Summarise findings and elaborate on implications and scope of model with regards to data sufficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.78125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 498,
   "position": {
    "height": "40px",
    "left": "933px",
    "right": "20px",
    "top": "120px",
    "width": "300px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
